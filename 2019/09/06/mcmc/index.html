<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="google-site-verification" content="iejSa-LmOb9d1GguAcEsQNUsQviccOieHkuG1c1E2YI">



  <meta name="msvalidate.01" content="83768A52AE58ADF203609FEF9C55FF47">












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="无监督学习,MCMC,马尔可夫链蒙特卡罗法,吉布斯抽样,Gibbs Sampling,">










<meta name="description" content="蒙特卡罗法(Monte Carlo method)，也称为统计模拟方法，是通过从概率模型的随机抽样进行近似数值计算的方法。 马尔可夫链蒙特卡罗法(MCMC)，则是以马尔可夫链为概率模型的蒙特卡罗法。 马尔可夫链蒙特卡罗法构建一个马尔可夫链，首先基于该马尔可夫链进行随机游走，产生样本的序列，然后使用该平稳分布的样本进行近似数值计算。 Metropolis-Hastings算法是最基本的马尔可夫链蒙特">
<meta name="keywords" content="无监督学习,MCMC,马尔可夫链蒙特卡罗法,吉布斯抽样,Gibbs Sampling">
<meta property="og:type" content="article">
<meta property="og:title" content="马尔可夫链蒙特卡罗法">
<meta property="og:url" content="https://jozeelin.github.io/2019/09/06/mcmc/index.html">
<meta property="og:site_name" content="Jozee&#39;s技术博客">
<meta property="og:description" content="蒙特卡罗法(Monte Carlo method)，也称为统计模拟方法，是通过从概率模型的随机抽样进行近似数值计算的方法。 马尔可夫链蒙特卡罗法(MCMC)，则是以马尔可夫链为概率模型的蒙特卡罗法。 马尔可夫链蒙特卡罗法构建一个马尔可夫链，首先基于该马尔可夫链进行随机游走，产生样本的序列，然后使用该平稳分布的样本进行近似数值计算。 Metropolis-Hastings算法是最基本的马尔可夫链蒙特">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://jozeelin.github.io/2019/09/06/mcmc/image/19-1.png">
<meta property="og:image" content="https://jozeelin.github.io/2019/09/06/mcmc/image/19-2.png">
<meta property="og:image" content="https://jozeelin.github.io/2019/09/06/mcmc/image/19-3.png">
<meta property="og:updated_time" content="2019-09-06T15:27:28.469Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="马尔可夫链蒙特卡罗法">
<meta name="twitter:description" content="蒙特卡罗法(Monte Carlo method)，也称为统计模拟方法，是通过从概率模型的随机抽样进行近似数值计算的方法。 马尔可夫链蒙特卡罗法(MCMC)，则是以马尔可夫链为概率模型的蒙特卡罗法。 马尔可夫链蒙特卡罗法构建一个马尔可夫链，首先基于该马尔可夫链进行随机游走，产生样本的序列，然后使用该平稳分布的样本进行近似数值计算。 Metropolis-Hastings算法是最基本的马尔可夫链蒙特">
<meta name="twitter:image" content="https://jozeelin.github.io/2019/09/06/mcmc/image/19-1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://jozeelin.github.io/2019/09/06/mcmc/">





  <title>马尔可夫链蒙特卡罗法 | Jozee's技术博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jozee's技术博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jozeelin.github.io/2019/09/06/mcmc/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jozee">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jozee's技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">马尔可夫链蒙特卡罗法</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-09-06T23:15:46+08:00">
                2019-09-06
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-09-06T23:27:28+08:00">
                2019-09-06
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/09/06/mcmc/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/09/06/mcmc/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
          <span id="busuanzi_container_page_pv">
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
            </span>
            阅读量: <span id="busuanzi_value_page_pv"></span>次
          </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>蒙特卡罗法(Monte Carlo method)，也称为统计模拟方法，是通过从概率模型的随机抽样进行近似数值计算的方法。</p>
<p>马尔可夫链蒙特卡罗法(MCMC)，则是以马尔可夫链为概率模型的蒙特卡罗法。</p>
<p>马尔可夫链蒙特卡罗法构建一个马尔可夫链，首先基于该马尔可夫链进行随机游走，产生样本的序列，然后使用该平稳分布的样本进行近似数值计算。</p>
<p>Metropolis-Hastings算法是最基本的马尔可夫链蒙特卡罗法。</p>
<p>吉布斯抽样(Gibbs sampling)是更简单、使用更广泛的马尔可夫链蒙特卡罗法。</p>
<p>马尔可夫链蒙特卡罗法被应用于概率分布的估计、定积分的近似计算、最优化问题的近似求解等问提，特别是被应用于统计学习中概率模型的学习与推理，是重要的统计学习计算方法。</p>
<h2 id="蒙特卡罗法"><a href="#蒙特卡罗法" class="headerlink" title="蒙特卡罗法"></a>蒙特卡罗法</h2><p>本节介绍蒙特卡罗法在随机抽样、数学期望估计、定积分计算的应用。</p>
<p>马尔可夫链蒙特卡罗法是蒙特卡罗法的一种方法。</p>
<h3 id="随机抽样"><a href="#随机抽样" class="headerlink" title="随机抽样"></a>随机抽样</h3><p>蒙特卡罗法要解决的问题是：<strong>假设概率分布的定义已知，通过抽样获得概率分布的随机样本，并通过得到的随机样本对概率分布的特征进行分析</strong>。比如，从样本得到经验分布，从而估计总体分布；或者从样本计算出样本均值，从而估计总体期望。所以，<strong>蒙特卡罗法的核心是随机抽样</strong>。</p>
<p>一般的蒙特卡罗法有直接抽样法、接受-拒绝抽样法、重要性抽样法等。</p>
<p>接受-拒绝抽样法、重要性抽样法适合于概率密度函数复杂(如密度函数含有多个变量，各变量互相不独立，密度函数形式复杂)，不能直接抽样的情况。</p>
<p><strong>以接受-拒绝抽样法(accept-reject sampling method)为例</strong>。假设有随机变量x，取值<script type="math/tex">x\in \mathcal{X}</script>，其概率密度函数为<script type="math/tex">p(x)</script>。目标是得到该概率分布的随机样本，以对这个概率分布进行分析。</p>
<p><strong>基本想法</strong>：假设p(x)不可以直接抽样。找一个可以直接抽样的分布，称为建议分布(proposal distribution)。假设q(x)是建议分布的概率密度函数，并且有q(x)的c倍一定大于等于p(x)，其中c&gt;0。如下图所示：</p>
<p><img src="image/19-1.png" alt="19-1"></p>
<p>按照q(x)进行抽样，假设得到结果是<script type="math/tex">x^{*}</script>，在按照<script type="math/tex">\frac{p(x^*)}{cq(x^{*})}</script>的比例随机决定是否接受<script type="math/tex">x^{*}</script>。直观上，落到<script type="math/tex">p(x^{*})</script>范围内就接受(绿色)，落到<script type="math/tex">p(x^{*})</script>范围外就拒绝(红色)。<strong>接受-拒绝法实际上是按照p(x)的涵盖面积(或涵盖体积)占cq(x)的涵盖面积(或涵盖体积)的比例进行抽样</strong>。</p>
<p><strong>算法19.1 (接受-拒绝法)</strong></p>
<p>输入：抽样的目标概率分布的概率密度函数p(x)</p>
<p>输出：概率分布的随机样本<script type="math/tex">x_1,x_2,\dots,x_n</script></p>
<p>参数：样本数n</p>
<ol>
<li>选择概率密度函数为q(x)的概率分布，作为建议分布，使其对任一x满足<script type="math/tex">cq(x)\ge p(x)</script>，其中c&gt;0。</li>
<li>按照建议分布q(x)随机抽样得到样本<script type="math/tex">x^{*}</script>，在按照均匀分布在(0,1)范围内抽样得到u。</li>
<li>如果<script type="math/tex">u \le \frac{p(x^*)}{cq(x^{*})}</script>，则将<script type="math/tex">x^{*}</script>作为抽样结果；否则，回到步骤(2)。</li>
<li>直至得到n个随机样本，结束。</li>
</ol>
<p><strong>接受-拒接法的优点是容易实现，缺点是效率不高。如果p(x)的涵盖面积(或涵盖体积)占cq(x)的涵盖面积(或涵盖体积)的比例很低时，会导致拒绝的比例很高，抽样效率很低</strong>。</p>
<h3 id="数学期望估计"><a href="#数学期望估计" class="headerlink" title="数学期望估计"></a>数学期望估计</h3><p>假设有随机变量x，取值<script type="math/tex">x\in \mathcal{X}</script>，其概率密度函数为p(x)，f(x)为定义在<script type="math/tex">\mathcal{X}</script>上的函数，目标是求函数f(x)关于密度函数p(x)的数学期望<script type="math/tex">E_{p(x)}[f(x)]</script>。</p>
<p>针对这个问题，蒙特卡罗法按照概率分布p(x)独立的抽取n个样本<script type="math/tex">x_1,x_2,\dots,x_n</script>，之后计算函数f(x)的样本均值<script type="math/tex">\hat{f}_n</script>。</p>
<script type="math/tex; mode=display">
\hat{f}_n = \frac{1}{n}\sum_{i=1}^n f(x_i) \tag{19-1}</script><p>作为数学期望<script type="math/tex">E_{p(x)}[f(x)]</script>的近似值。</p>
<p>根据大数定律可知，当样本容量增大时，样本均值以概率1收敛于数学期望：</p>
<script type="math/tex; mode=display">
\hat{f}_n \to E_{p(x)}[f(x)] \ , n\to \infty \tag{19-2}</script><p>因此，得到数学期望的近似计算方法：</p>
<script type="math/tex; mode=display">
E_{p(x)}[f(x)] \approx \frac{1}{n}\sum_{i=1}^n f(x_i) \tag{19-3}</script><h3 id="积分计算"><a href="#积分计算" class="headerlink" title="积分计算"></a>积分计算</h3><p>应用在定积分的近似计算上的蒙特卡罗法，也称为蒙特卡罗积分。</p>
<p>假设有一个函数h(x)，目标是计算函数的积分：</p>
<script type="math/tex; mode=display">
\int_{\mathcal{X}} h(x) dx</script><p>如果能够<strong>将函数h(x)分解成一个函数f(x)和一个概率密度函数p(x)的乘积的形式</strong>，那么就有：</p>
<script type="math/tex; mode=display">
\int_{\mathcal{X}}h(x)dx = \int_{\mathcal{X}} f(x)p(x)dx = E_{p(x)}[f(x)]\tag{19-4}</script><p>于是，函数h(x)的积分可以表示为函数f(x)关于概率密度函数p(x)的数学期望。</p>
<p>实际上，给定一个概率密度函数p(x)，只要取<script type="math/tex">f(x) = \frac{h(x)}{p(x)}</script>，就可以得式(19-4)。也就是说，任何一个函数的积分都可以表示为某一个函数的数学期望的形式。而函数的数学期望又可以通过函数的样本均值估计。于是，<strong>就可以利用样本均值来近似计算积分</strong>。这就是蒙特卡罗积分的基本想法：</p>
<script type="math/tex; mode=display">
\int_{\mathcal{X}}h(x)dx = E_{p(x)}[f(x)] \approx \frac{1}{n}\sum_{i=1}^n f(x_i) \tag{19-5}</script><h2 id="马尔可夫链"><a href="#马尔可夫链" class="headerlink" title="马尔可夫链"></a>马尔可夫链</h2><h3 id="基本定义"><a href="#基本定义" class="headerlink" title="基本定义"></a>基本定义</h3><p><strong>定义19.1(马尔可夫链)</strong> 考虑一个随机变量的序列<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，这里<script type="math/tex">X_t</script>表示时刻t的随机变量，t=1,2,…。每个随机变量<script type="math/tex">X_t(t=0,1,2,\dots)</script>的取值集合相同，称为状态空间，表示为S，随机变量可以是离散的，也可以是连续的。以上随机变量的序列构成随机过程(stochastic process)。</p>
<p>假设在时刻0的随机变量<script type="math/tex">X_0</script>遵循概率分布<script type="math/tex">P(X_0) = \pi_0</script>，称为初始化状态分布。在某个时刻<script type="math/tex">t \ge 1</script>的随机变量<script type="math/tex">X_t</script>与前一个时刻的随机变量<script type="math/tex">X_{t-1}</script>之间有条件分布<script type="math/tex">P(X_t|X_{t-1})</script>，如果<script type="math/tex">X_t</script>只依赖于<script type="math/tex">X_{t-1}</script>，而不依赖于过去的随机变量<script type="math/tex">\{X_0,X_1,\dots,X_{t-2}\}</script>，这一性质称为马尔可夫性，即</p>
<script type="math/tex; mode=display">
P(X_t|X_0,X_1,\dots,X_{t-1}) = P(X_t|X_{t-1}) \ , t=1,2,\dots \tag{19-6}</script><p>具有马尔可夫的随机序列<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>称为马尔可夫链，或马尔可夫过程。</p>
<p>条件概率分布<script type="math/tex">P(X_t|X_{t-1})</script>称为马尔可夫链的转移概率分布。<strong>转移概率分布决定了马尔可夫链的特性</strong>。</p>
<blockquote>
<p>马尔可夫性的直观解释是：<strong>未来只依赖于现在(假设现在已知)，而与过去无关</strong>。</p>
</blockquote>
<p>若转移概率分布<script type="math/tex">P(X_t|X_{t-1})</script>与t无关，即:</p>
<script type="math/tex; mode=display">
P(X_{t+s}|X_{t-1+s}) = P(X_t|X_{t-1}) \ , t=1,2,\dots ;s=1,2,\dots \tag{19-7}</script><p>则称<strong>该马尔可夫链为时间齐次的马尔可夫链</strong>。</p>
<p>n阶马尔可夫链，满足n阶马尔可夫性(对照一阶马尔可夫性(19-6))：</p>
<script type="math/tex; mode=display">
P(X_t|X_0,X_1,\dots,X_{t-1}) = P(X_t|X_{t-n},\dots,X_{t-1}) \tag{19-8}</script><p><strong>本书中提到的马尔可夫链都是时间齐次的，且只考虑一阶马尔可夫链</strong>。</p>
<blockquote>
<p>容易验证n阶马尔可夫链可以转换为一阶马尔可夫链。</p>
</blockquote>
<h3 id="离散状态马尔可夫链"><a href="#离散状态马尔可夫链" class="headerlink" title="离散状态马尔可夫链"></a>离散状态马尔可夫链</h3><h4 id="转移概率矩阵和状态分布"><a href="#转移概率矩阵和状态分布" class="headerlink" title="转移概率矩阵和状态分布"></a>转移概率矩阵和状态分布</h4><p>离散状态马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，随机变量<script type="math/tex">X_t(t=0,1,2,\dots)</script>定义在离散空间S，转移概率分布可以由矩阵表示。</p>
<p>若马尔可夫链在时刻(t-1)处于状态j，在时刻t移动到状态i，将转移概率记作:</p>
<script type="math/tex; mode=display">
p_{ij} = (X_t=i|X_{t-1}=j) \ , i=1,2,\dots;j=1,2,\dots \tag{19-9}</script><p>满足 </p>
<script type="math/tex; mode=display">
p_{ij} \ge 0 \ , \sum_{i}p_{ij} = 1</script><p>马尔可夫链的转移概率<script type="math/tex">p_{ij}</script>可以由矩阵表示，即：</p>
<script type="math/tex; mode=display">
P = \begin{bmatrix}p_{11}&p_{12}&\dots\\p_{21}&p_{22}&\dots\\p_{31}&p_{32}&\dots\\\dots&\dots&\dots\end{bmatrix} \tag{19-10}</script><p>称为马尔可夫链的转移概率矩阵，转移概率矩阵P满足条件<script type="math/tex">p_{ij} \ge 0 \ , \sum_{i}p_{ij} = 1</script>。满足这两个条件的矩阵称为随机矩阵。</p>
<p>考虑马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>在时刻<script type="math/tex">t(t=0,1,2,\dots)</script>的概率分布，称为时刻t的概率分布，记作：</p>
<script type="math/tex; mode=display">
\pi(t) = \begin{bmatrix}\pi_1(t)\\\pi_2(t)\\\vdots\end{bmatrix} \tag{19-11}</script><p>其中<script type="math/tex">\pi_i(t)</script>表示时刻t状态为i的概率<script type="math/tex">P(X_t=i)</script>，</p>
<script type="math/tex; mode=display">
\pi_i(t) = P(X_t=i) \ , i=1,2,\dots</script><p>特别地，马尔可夫链的初始状态分布可以表示为：</p>
<script type="math/tex; mode=display">
\pi(0) = \begin{bmatrix}\pi_1(0)\\\pi_2(0)\\\vdots\end{bmatrix} \tag{19-12}</script><p>其中<script type="math/tex">\pi_i(0)</script>表示时刻0状态为i的概率<script type="math/tex">P(X_0=i)</script>。<strong>通常初始分布<script type="math/tex">\pi(0)</script>的向量只有一个分量是1，其余分量都是0，表示马尔可夫链从一个具体状态开始*。</strong></p>
<p>有限离散状态的马尔可夫链可以由有向图表示。结点表示状态，边表示状态之间的转移，边上的数值表示转移概率。从一个初始状态出发，根据有向边上定义的概率在状态之间的随机跳转(或随机转移)，就可以产生状态的序列。</p>
<p>马尔可夫链实际上是刻画随时间在状态之间转移的模型，假设未来的转移状态只依赖于现在的状态，而与过去的状态无关。</p>
<h4 id="平稳分布"><a href="#平稳分布" class="headerlink" title="平稳分布"></a>平稳分布</h4><p><strong>定义19.2(平稳分布)</strong> 设有马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，其状态空间为S，转移概率矩阵为<script type="math/tex">P=(p_{ij})</script>，如果存在状态空间S上的一个分布：</p>
<script type="math/tex; mode=display">
\pi = \begin{bmatrix}\pi_1\\\pi_2\\\vdots\end{bmatrix}</script><p>使得</p>
<script type="math/tex; mode=display">
\pi = P\pi \tag{19-15}</script><p>则称<script type="math/tex">\pi</script>为马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>的平稳分布。</p>
<blockquote>
<p>直观上，如果马尔可夫链的平稳分布存在，那么以该平稳分布作为初始分布，面向未来进行随机状态转移，之后任何一个时刻的状态分布都是该平稳分布。</p>
</blockquote>
<p><strong>引理19.1</strong> 给定一个马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，状态空间为S，转移概率矩阵为<script type="math/tex">P=(p_{ij})</script>，则分布<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>为X的平稳分布的充分必要条件是<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>是下列方程组的解：</p>
<script type="math/tex; mode=display">
x_i = \sum_j p_{ij}x_j \ , i=1,2,\dots \tag{19-16}</script><script type="math/tex; mode=display">
x_i \ge 0 \ , i=1,2,\dots \tag{19-17}</script><script type="math/tex; mode=display">
\sum_i x_i = 1 \tag{19-18}</script><p><strong>证明：</strong></p>
<p><strong>必要性</strong>。</p>
<p>假设<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>是平稳分布，显然满足式(19-17)和式(19-18)，又根据平稳分布的定义，可得：</p>
<script type="math/tex; mode=display">
x_i = \sum_j p_{ij}x_j \ , i=1,2,\dots</script><p>即<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>满足式(19-16)。</p>
<p><strong>充分性</strong>。</p>
<p>由式(19-17)和式(19-18)知<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>是一概率分布。假设<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>为<script type="math/tex">X_t</script>的分布，则：</p>
<script type="math/tex; mode=display">
P(X_t = i) = \pi_i = \sum_j p_{ij}\pi_j = \sum_j p_{ij}P(X_{t-1}=j) \ , i=1,2,\dots</script><p>同时<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>也为<script type="math/tex">X_{t-1}</script>的分布。事实上这对任意t成立。所以<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>是马尔可夫链的平稳分布。</p>
<blockquote>
<p>引理19.1给出一个求马尔可夫链平稳分布的方法</p>
</blockquote>
<h3 id="连续状态马尔可夫链"><a href="#连续状态马尔可夫链" class="headerlink" title="连续状态马尔可夫链"></a>连续状态马尔可夫链</h3><p>连续状态马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，随机变量<script type="math/tex">X_t(t=0,1,2,\dots)</script>定义在连续状态空间S，转移概率分布由概率转移核伙转移核(transition kernel)表示。</p>
<p>设S是连续状态空间，对任意的<script type="math/tex">x\in S,A \subset S</script>，转移核<script type="math/tex">P(x,A)</script>定义为：</p>
<script type="math/tex; mode=display">
P(x,A)  = \int_A p(x,y)dy \tag{19-19}</script><p>其中<script type="math/tex">p(x,\bullet)</script>是概率密度函数，满足<script type="math/tex">p(x,\bullet)\ge 0,P(x,S)=\int_S p(x,y)dy=1</script>。转移核P(x,A)表示从<script type="math/tex">x \sim A</script>的转移概率：</p>
<script type="math/tex; mode=display">
P(X_t=A|X_{t-1}=x) = P(x,A) \tag{19-20}</script><p>有时，也将概率密度函数<script type="math/tex">p(x,\bullet)</script>称为转移核。</p>
<p>若马尔可夫链的状态空间S 上概率分布<script type="math/tex">\pi(x)</script>满足条件：</p>
<script type="math/tex; mode=display">
\pi(y) = \int p(x,y)\pi(x)dx, \forall y \in S \tag{19-21}</script><p>则称分布<script type="math/tex">\pi(x)</script>为该马尔可夫链的平稳分布。等价的：</p>
<script type="math/tex; mode=display">
\pi(A) = \int P(x,A)\pi(x)dx, \forall A \subset S \tag{19-22}</script><p>或简写为：</p>
<script type="math/tex; mode=display">
\pi = P\pi \tag{19-23}</script><h3 id="马尔可夫链的性质"><a href="#马尔可夫链的性质" class="headerlink" title="马尔可夫链的性质"></a>马尔可夫链的性质</h3><p>以下为离散状态马尔可夫链的性质。</p>
<h4 id="不可约"><a href="#不可约" class="headerlink" title="不可约"></a>不可约</h4><p><strong>定义19.3(不可约)</strong> 设有马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，状态空间为S，对于任意状态<script type="math/tex">i,j\in S</script>，如果存在一个时刻 t(t&gt;0)满足：</p>
<script type="math/tex; mode=display">
P(X_t=i|X_0=j) > 0 \tag{19-24}</script><p>也就是说，时刻0从状态j出发，时刻t到达状态i的概率大于0，则称此马尔可夫链X是不可约的，否则称马尔可夫链是可约的。</p>
<blockquote>
<p>直观上，一个不可约的马尔可夫链，从任意状态出发，当经过充分长时间后，可以到达任意状态。</p>
</blockquote>
<h4 id="非周期"><a href="#非周期" class="headerlink" title="非周期"></a>非周期</h4><p><strong>定义19.4(非周期)</strong> 设有马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，状态空间为S,对于任意状态<script type="math/tex">i,j\in S</script>，如果从时刻0从状态i出发，时刻t返回状态i的所有时间长<script type="math/tex">\{t:P(X_t=i|X_0=i)>0\}</script>的最大公约数是1，则称此马尔可夫链X是非周期的，否则称马尔可夫链是周期的。</p>
<blockquote>
<p>直观上，一个非周期性的马尔可夫链，不存在一个状态，从这一个状态出发，再返回到这个状态时所经历的时间长呈一定的周期性。</p>
</blockquote>
<p><strong>定理19.2</strong> 不可约且非周期的有限状态马尔可夫链，有唯一平稳分布存在。</p>
<h4 id="正常返-positive-recurrent"><a href="#正常返-positive-recurrent" class="headerlink" title="正常返(positive recurrent)"></a>正常返(positive recurrent)</h4><p><strong>定义19.5(正常返)</strong> 设有马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，状态空间为S，对于任意状态<script type="math/tex">i,j \in S</script>，定义概率<script type="math/tex">p_{ij}^t</script>为时刻0从状态j出发，时刻t首次转移到状态i的概率，即<script type="math/tex">p_{ij}^t=P(X_t=i,X_s\ne i, s=1,2,\dots,t-1|X_0=j) \ , t=1,2,\dots</script>。若对所有状态i,j都满足<script type="math/tex">\lim_{t\to \infty} p_{ij}^t >0</script>，则称马尔可夫链X是正常返(positive recurrent)的。</p>
<blockquote>
<p>直观上，一个正常返的马尔可夫链，其中任意一个状态，从其它任意一个状态出发，当时间趋于无穷时，首次转移到这个状态的概率不为0。</p>
</blockquote>
<p><strong>当时间趋于无穷时，转移到任意一个状态的概率不为0，马尔可夫链是正常返的</strong>。</p>
<p>当<script type="math/tex">p\ll q</script>时，不存在平稳分布，马尔可夫链不是正常返的。</p>
<p><strong>定理19.3</strong> 不可约、非周期且正常返的马尔可夫链，有唯一平稳分布存在。</p>
<h4 id="遍历定理"><a href="#遍历定理" class="headerlink" title="遍历定理"></a>遍历定理</h4><p><strong>定理19.4(遍历定理)</strong> 设有马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，状态空间为S，若马尔可夫链X是不可约、非周期且正常返的，则该马尔可夫链有唯一平稳分布<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>，并且<strong>转移概率的极限分布是马尔可夫链的平稳分布</strong>。</p>
<script type="math/tex; mode=display">
\lim_{t \to \infty} P(X_t=i|X_0=j) = \pi_i \ , i=1,2,\dots;j=1,2,\dots \tag{19-25}</script><p>若f(X)是定义在状态空间上的函数，<script type="math/tex">E_{\pi}[|f(X)|] < \infty</script>，则</p>
<script type="math/tex; mode=display">
P\{\hat{f}_t\to E_{\pi}[|f(X)|] \} = 1 \tag{19-26}</script><script type="math/tex; mode=display">
\hat{f}_t = \frac{1}{t} \sum_{s=1}^t f(x_s)</script><p>其中，<script type="math/tex">E_{\pi}[|f(X)|] = \sum_i f(i)\pi_i</script>是f(X)关于平稳分布<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>的数学期望，式(19-26)表示：</p>
<script type="math/tex; mode=display">
\hat{f}_t\to E_{\pi}[|f(X)|] \ , t\to \infty \tag{19-27}</script><p>几乎处处成立或以概率1成立。</p>
<blockquote>
<p>直观上，满足相应条件的马尔可夫链，当时间趋于无穷时，马尔可夫链的状态分布趋近于平稳分布。</p>
<p>随机变量的函数的样本均值以概率1收敛于该函数的数学期望。</p>
<p>样本均值可以认为是时间均值，而数学期望是空间均值。</p>
<p>遍历定理表示了遍历性的含义：<strong>当时间趋于无穷时，时间均值等于空间均值</strong>。</p>
<p>遍历定理的三个条件：不可约、非周期、正常返，保证了当时间趋于无穷时达到任意一个状态的概率不为0.</p>
</blockquote>
<p>在实际应用遍历原理时，取一个足够大的整数m，经过m次迭代之后认为状态分布就是平稳分布，这时计算从m+1次迭代到第n次迭代的均值，即：</p>
<script type="math/tex; mode=display">
\hat{E}f = \frac{1}{n-m}\sum_{i=m+1}^n f(x_i) \tag{19-28}</script><p>称为<strong>遍历均值</strong>。</p>
<h4 id="可逆马尔可夫链"><a href="#可逆马尔可夫链" class="headerlink" title="可逆马尔可夫链"></a>可逆马尔可夫链</h4><p><strong>定义19.6(可逆马尔可夫链)</strong> 设有马尔可夫链<script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，状态空间为S，转移概率矩阵为P，如果有状态分布<script type="math/tex">\pi=(\pi_1,\pi_2,\dots)^{\top}</script>，对于任意状态<script type="math/tex">i,j\in S</script>，对任意一个时刻t满足：</p>
<script type="math/tex; mode=display">
P(X_t=i|X_{t-1}=j)\pi_j = P(X_{t-1}=j|X_t=i)\pi_i \ , i,j=1,2,\dots \tag{19-29}</script><p>或简写为</p>
<script type="math/tex; mode=display">
p_{ji}\pi_j = p_{ij}\pi_i \ , i,j=1,2,\dots \tag{19-30}</script><p>则称此马尔可夫链X为可逆马尔可夫链，式(19-30)称为细致平衡方程(detail balance equation)。</p>
<blockquote>
<p>直观上，如果有可逆的马尔可夫链，那么以该马尔可夫链的平稳分布作为初始分布，进行随机状态转移，无论是面向未来还是面向过去，任何一个时刻的状态分布都是该平稳分布。</p>
</blockquote>
<p><strong>定理19.5(细致平衡方程)</strong> 满足细致平衡方程的状态分布<script type="math/tex">\pi</script>就是该马尔可夫链的平稳分布，即 </p>
<script type="math/tex; mode=display">
P\pi = \pi</script><p><strong>证明</strong>：</p>
<script type="math/tex; mode=display">
(P\pi)_i = \sum_{j}p_{ij}\pi_j = \sum_jp_{ji}\pi_i = \pi_i\sum_j p_{ji} = \pi_i \ , i=1,2,\dots \tag{19.31}</script><p>定理19.5说明，<strong>可逆马尔可夫链一定有唯一平稳分布，给出了一个马尔可夫链有平稳分布的充分条件(不是必要条件)。也就是说，可逆马尔可夫链满足遍历定理19.4的条件</strong>。</p>
<h2 id="马尔可夫链蒙特卡罗法"><a href="#马尔可夫链蒙特卡罗法" class="headerlink" title="马尔可夫链蒙特卡罗法"></a>马尔可夫链蒙特卡罗法</h2><h3 id="基本想法"><a href="#基本想法" class="headerlink" title="基本想法"></a>基本想法</h3><p>假设多元随机变量x，满足<script type="math/tex">x\in \mathcal{X}</script>，其概率密度函数为p(x)，f(x)为定义在<script type="math/tex">x\in \mathcal{X}</script>上的函数，目标是获得概率分布p(x)的样本集合，以及求函数f(x)的数学期望<script type="math/tex">E_{p(x)}[f(x)]</script>。</p>
<p>应用马尔可夫链蒙特卡罗法解决这个问题：在随机变量x的状态空间S上<strong>定义一个满足遍历定理的马尔可夫链</strong><script type="math/tex">X=\{X_0,X_1,\dots,X_t,\dots\}</script>，使其平稳分布就是抽样的目标分布p(x)。然后，在这个马尔可夫链上进行随机游走，每个时刻得到一个样本。<strong>根据遍历定理</strong>，当时间趋于无穷时，样本的分布趋近平稳分布，样本的函数均值趋近于函数的数学期望。所以，**当时间足够长时(时刻大于某个正整数m)，在之后的时间(时刻小于等于某个正整数n,n&gt;m)里随机游走得到的样本集合<script type="math/tex">\{x_{m+1},x_{m+2},\dots,x_n\}</script>就是目标概率分布的抽样结果，得到的函数均值(遍历均值)就是要计算的数学期望值:</p>
<script type="math/tex; mode=display">
\hat{E}f = \frac{1}{n-m}\sum_{i=m+1}^n f(x_i) \tag{19-32}</script><p>到i时刻m为止的时间段称为燃烧期。</p>
<h3 id="基本步骤"><a href="#基本步骤" class="headerlink" title="基本步骤"></a>基本步骤</h3><ol>
<li><p>首先，在随机变量x的状态空间S上构造一个满足遍历定理的马尔可夫链，使其平稳分布为目标分布p(x)</p>
</li>
<li><p>从状态空间的某一点<script type="math/tex">x_0</script>出发，用构造的马尔可夫链进行随机游走，产生样本序列<script type="math/tex">x_0,x_1,\dots,x_t,\dots</script>。</p>
</li>
<li><p>应用马尔可夫链的遍历定理，确定正整数m和n，(m&lt;n)，得到样本集合${x<em>{m+1},x</em>{m+1},\dots,x_n}$，求得函数f(x)的均值(遍历均值)</p>
<script type="math/tex; mode=display">
\hat{E}f = \frac{1}{n-m}\sum_{i=m+1}^n f(x_i) \tag{19-33}</script></li>
</ol>
<p>就是马尔可夫链蒙特卡罗法的计算公式。</p>
<p>这里有几个重要问题：</p>
<ol>
<li>如何定义马尔可夫链，保证马尔可夫链蒙特卡罗法的条件成立</li>
<li>如何确定收敛步数m，保证样本抽样的无偏性</li>
<li>如何确定迭代步数n，保证遍历均值计算的精度</li>
</ol>
<h3 id="马尔可夫链蒙特卡罗法与统计学习"><a href="#马尔可夫链蒙特卡罗法与统计学习" class="headerlink" title="马尔可夫链蒙特卡罗法与统计学习"></a>马尔可夫链蒙特卡罗法与统计学习</h3><p>假设观测数据由随机变量<script type="math/tex">y\in \mathcal{Y}</script>表示，模型由随机变量<script type="math/tex">x\in \mathcal{X}</script>表示，贝叶斯学习通过贝叶斯定理计算给定数据条件下模型的后验概率，并选择后验概率最大的模型。</p>
<p>后验概率：</p>
<script type="math/tex; mode=display">
p(x|y) = \frac{p(x)p(y|x)}{\int_{\mathcal{X}}p(y|x^{'})p(x^{'})dx^{'}} \tag{19-34}</script><p>贝叶斯学习中经常需要进行三种积分运算：规范化(normalization)，边缘化，数学期望。</p>
<p>后验概率计算中需要规范化计算：</p>
<script type="math/tex; mode=display">
\int_{\mathcal{X}}p(y|x^{'})p(x^{'})dx^{'} \tag{19-35}</script><p>如果有隐变量<script type="math/tex">z \in Z</script>，后验概率的计算需要边缘化计算：</p>
<script type="math/tex; mode=display">
p(x|y) = \int_{\mathcal{Z}}p(x,z|y)dz \tag{19-36}</script><p>如果有一个函数f(x)，可以计算该函数的关于后验概率分布的数学期望：</p>
<script type="math/tex; mode=display">
E_{p(x|y)}[f(x)] = \int_{\mathcal{Z}}f(x)p(x|y) dx \tag{19-37}</script><p>当观测数据和模型都很复杂的时候，以上积分计算会变得困难。而<strong>马尔可夫链蒙特卡罗法为这些计算提供了一个通用的有效解决方案</strong>。</p>
<h2 id="Metropolis-Hastings算法"><a href="#Metropolis-Hastings算法" class="headerlink" title="Metropolis-Hastings算法"></a>Metropolis-Hastings算法</h2><p>Metropolis-Hastings是马尔可夫链蒙特卡罗法的代表算法。</p>
<h3 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h3><h4 id="马尔可夫链-1"><a href="#马尔可夫链-1" class="headerlink" title="马尔可夫链"></a>马尔可夫链</h4><p>假设要抽样的概率分布为p(x)。Metropolis-Hastings算法采用转移核为<script type="math/tex">p(x,x^{'})</script>的马尔可夫链：</p>
<script type="math/tex; mode=display">
p(x,x^{'}) = q(x,x^{'})\alpha(x,x^{'}) \tag{19-38}</script><p>其中<script type="math/tex">q(x,x^{'})</script>和<script type="math/tex">\alpha(x,x^{'})</script>分别称为建议分布(proposal distribution)和接受分布(acceptance distribution)。</p>
<p>建议分布<script type="math/tex">q(x,x^{'})</script> 是另一个马尔可夫链的转移核，并且<script type="math/tex">q(x,x^{'})</script>是不可约的，即其概率值恒不为0，同时是一个容易抽样的分布。</p>
<p>接受分布<script type="math/tex">\alpha(x,x^{'})</script>是</p>
<script type="math/tex; mode=display">
\alpha(x,x^{'}) = \min \left\{1,\frac{p(x^{'})q(x^{'},x)}{p(x)q(x,x^{'})}\right\} \tag{19-39}</script><p>这时转移核<script type="math/tex">p(x,x^{'})</script>可以写成</p>
<script type="math/tex; mode=display">
p(x,x^{'}) = \left\{\begin{aligned}&q(x,x^{'}),p(x^{'})q(x^{'},x)\ge p(x)q(x,x^{'})\\&q(x^{'},x)\frac{p(x^{'})}{p(x)},p(x^{'})q(x^{'},x)< p(x)q(x,x^{'})\end{aligned}\right . \tag{19-40}</script><p>转移核为<script type="math/tex">p(x,x^{'})</script>的马尔可夫链上的随机游走以以下方式进行。</p>
<p>如果在时刻(t-1)处于状态x,即<script type="math/tex">x_{t-1} = x</script>，则先按建议分布<script type="math/tex">q(x,x^{'})</script>抽样产生一个候选状态<script type="math/tex">x^{'}</script>，然后按照接受分布<script type="math/tex">\alpha(x,x^{'})</script>抽样决定是否接受状态<script type="math/tex">x^{'}</script>。以概率<script type="math/tex">\alpha(x,x^{'})</script>接受<script type="math/tex">x^{'}</script>，决定时刻t转移到状态<script type="math/tex">x^{'}</script>，而以概率<script type="math/tex">1-\alpha(x,x^{'})</script>拒绝<script type="math/tex">x^{'}</script>，决定时刻t仍停留在状态x。</p>
<p>具体地，在区间(0,1)上的均匀分布中抽取一个随机数u，决定时刻t的状态：</p>
<script type="math/tex; mode=display">
x_t = \left\{\begin{aligned}&x^{'}, u\le \alpha(x,x^{'})\\&x, u>\alpha(x,x^{'}) \end{aligned}\right .</script><p>可以证明，转移核为<script type="math/tex">p(x,x^{'})</script>的马尔可夫链是可逆马尔可夫链(<strong>满足遍历原理</strong>)，其平稳分布就是p(x)，即要抽样的目标分布。</p>
<p><strong>定理19.6</strong> 由转移核(19-38)~(19-40)构成的马尔可夫链是可逆的，即</p>
<script type="math/tex; mode=display">
p(x)p(x,x^{'}) = p(x^{'})p(x^{'},x) \tag{19-41}</script><p>并且p(x)是该马尔可夫链的平稳分布。</p>
<p><strong>证明</strong>：若<script type="math/tex">x=x^{'}</script>，则式(19-41)显然成立。</p>
<p>设<script type="math/tex">x \ne x^{'}</script>，则</p>
<script type="math/tex; mode=display">
\begin{aligned}
p(x)p(x,x^{'}) &= p(x)q(x,x^{'}) \min \left\{1,\frac{p(x^{'})q(x^{'},x)}{p(x)q(x,x^{'})}\right\}\\
&= \min \left\{p(x)q(x,x^{'}),p(x^{'})q(x^{'},x)\right\}\\
&= p(x^{'})q(x^{'},x) \min \left\{\frac{p(x)q(x,x^{'})}{p(x^{'})q(x^{'},x)},1\right\}\\
&= p(x^{'})p(x^{'},x)
\end{aligned}</script><p>式(19-41)成立。</p>
<p>由式(19-41)知，</p>
<script type="math/tex; mode=display">
\begin{aligned}
\int p(x)p(x,x^{'})dx &= \int p(x^{'})p(x^{'},x) dx\\
&= p(x^{'})\int p(x^{'},x) dx\\
&= p(x^{'})
\end{aligned}</script><p>依据平稳分布的定义(19-21)，p(x)是马尔可夫链的平稳分布。</p>
<h5 id="建议分布"><a href="#建议分布" class="headerlink" title="建议分布"></a>建议分布</h5><p>建议分布<script type="math/tex">q(x,x^{'})</script>有多种可能的形式，这里介绍两种常用形式：</p>
<ol>
<li><p>第一种形式：假设建议分布是对称的，即对任意的x和 <script type="math/tex">x^{'}</script>有</p>
<script type="math/tex; mode=display">
q(x,x^{'}) = q(x^{'},x) \tag{19-42}</script><p>这样的建议分布称为Metropolis选择，也是Metropolis-Hastings算法最初采用的建议分布。这时，接受分布<script type="math/tex">\alpha(x,x^{'})</script>简化为：</p>
<script type="math/tex; mode=display">
\alpha(x,x^{'}) = \min \left\{1,\frac{p(x^{'})}{p(x)}\right\} \tag{19-43}</script><ul>
<li><p>Metropolis选择的一个特例是<script type="math/tex">q(x,x^{'})</script>取条件概率分布<script type="math/tex">p(x^{'},x)</script>，定义为多元正态分布，其均值为x，其协方差矩阵是常数矩阵。</p>
</li>
<li><p>Metropolis选择的另一个特例是令<script type="math/tex">q(x,x^{'})=q(|x-x^{'}|)</script>，这时算法称为随机游走Metropolis算法。例如，</p>
<script type="math/tex; mode=display">
q(x,x^{'}) \propto \exp(-\frac{(x^{'}-x)^2}{2})</script><p>Metropolis选择的特点是当<script type="math/tex">x^{'}</script>与x接近时，<script type="math/tex">q(x,x^{'})</script>的概率值高，否则<script type="math/tex">q(x,x^{'})</script>的概率值低。状态转移在附近点的可能性更大。</p>
</li>
</ul>
</li>
<li><p>第二种形式：独立抽样。假设<script type="math/tex">q(x,x^{'})</script>与当前状态x无关，即<script type="math/tex">q(x,x^{'})=q(x^{'})</script>。建议分布的计算按照<script type="math/tex">q(x^{'})</script>独立抽样进行。此时，接受分布<script type="math/tex">\alpha(x,x^{'})</script>可以写成:</p>
<script type="math/tex; mode=display">
\alpha(x,x^{'}) = \min \left\{1,\frac{w(x^{'})}{w(x)}\right\} \tag{19-44}</script><p>其中，<script type="math/tex">w(x^{'}) = p(x^{'})/q(x^{'}),w(x) = p(x)/q(x)</script>。</p>
<p>独立抽样实现简单，但通常收敛速度慢，通常选择接近目标分布p(x)的分布作为建议分布q(x)。</p>
</li>
</ol>
<h4 id="满条件分布"><a href="#满条件分布" class="headerlink" title="满条件分布"></a>满条件分布</h4><p>马尔可夫链蒙特卡罗法的目标分布通常是多元联合概率分布<script type="math/tex">p(x) = p(x_1,x_2,\dots,x_k)</script>，其中<script type="math/tex">x=(x_1,x_2,\dots,x_k)^{\top}</script>为k维随机变量。如果条件概率分布<script type="math/tex">p(x_I|x_{-I})</script>中所有k个变量全部出现，其中<script type="math/tex">x_I=\{x_i,i\in I\},x_{-I} = \{x_i,i\notin I\},I\subset K = \{1,2,\dots,k\}</script>，那么称这种条件概率分布为满条件分布(full conditional distribution)。</p>
<p>满条件分布有以下性质：对任意的<script type="math/tex">x,x^{'}\in \mathcal{X}</script>和任意的<script type="math/tex">I \subset K</script>，有：</p>
<script type="math/tex; mode=display">
p(x_I | x_{-I}) = \frac{p(x)}{\int p(x)dx_I} \propto p(x) \tag{19-45}</script><p>而且，对任意的<script type="math/tex">x,x^{'}\in \mathcal{X}</script>和任意的<script type="math/tex">I \subset K</script>，有：</p>
<script type="math/tex; mode=display">
\frac{p(x^{'}_I|x^{'}_{-I})}{p(x_I|x_{-I})} = \frac{p(x^{'})}{p(x)} \tag{19-46}</script><p>Metropolis-Hastings算法中，可以利用性质(19-46)，简化计算，提高计算效率。</p>
<p>具体地，通过满条件分布概率的比<script type="math/tex">\frac{p(x^{'}_I|x^{'}_{-I})}{p(x_I|x_{-I})}</script>计算联合概率的比<script type="math/tex">\frac{p(x^{'})}{p(x)}</script>，而前者更容易计算。</p>
<h3 id="Metropolis-Hastings算法-1"><a href="#Metropolis-Hastings算法-1" class="headerlink" title="Metropolis-Hastings算法"></a>Metropolis-Hastings算法</h3><p><strong>算法19.2(Metropolis-Hastings算法)</strong></p>
<p>输入：抽样的目标分布的密度函数p(x)，函数f(x)；</p>
<p>输出：p(x)的随机样本<script type="math/tex">x_{m+1},x_{m+2},\dots,x_n</script>，函数样本均值<script type="math/tex">f_{mn}</script>；</p>
<p>参数：收敛步数m，迭代步数n。</p>
<ol>
<li><p>任意选择一个初始值 <script type="math/tex">x_0</script></p>
</li>
<li><p>对i=1,2,…,n循环执行</p>
<ol>
<li><p>设状态<script type="math/tex">x_{i-1}=x</script>，按照建议分布<script type="math/tex">q(x,x6{'})</script>随机抽取一个候选状态<script type="math/tex">x^{'}</script>。</p>
</li>
<li><p>计算接受概率</p>
<script type="math/tex; mode=display">
\alpha(x,x^{'}) = \min \left\{1,\frac{p(x^{'})q(x^{'},x)}{p(x)q(x,x^{'})}\right\}</script></li>
<li><p>从区间(0,1)中按均匀分布随机抽取一个数u。</p>
<p>若<script type="math/tex">u\le \alpha(x,x^{'})</script>，则状态<script type="math/tex">x_i=x^{'}</script>；否则，状态<script type="math/tex">x_i=x</script>。</p>
</li>
</ol>
</li>
<li><p>得到样本集合<script type="math/tex">x_{m+1},x_{m+2},\dots,x_n</script></p>
<p>计算</p>
<script type="math/tex; mode=display">
f_{mn} = \frac{1}{n-m}\sum_{i=m+1}^n f(x_i)</script></li>
</ol>
<h3 id="单分量Metropolis-Hastings算法"><a href="#单分量Metropolis-Hastings算法" class="headerlink" title="单分量Metropolis-Hastings算法"></a>单分量Metropolis-Hastings算法</h3><p>在Metropolis-Hastings算法中，通常需要对<strong>多元变量分布</strong>进行抽样，<strong>有时对多元变量分布的抽样是困难的</strong>。因此，可以<strong>对多元变量的每一变量的条件分布依次分别进行抽样，从而实现对整个多元变量的一次抽样，这种方法叫做单分量Metropolis-Hastings算法</strong>。</p>
<p>假设马尔可夫链的状态由k维随机变量表示：</p>
<script type="math/tex; mode=display">
x = (x_1,x_2,\dots,x_k)^{\top}</script><p>其中<script type="math/tex">x_j</script>表示随机变量x的第j个分量，j=1,2,…,k，而<script type="math/tex">x^{(i)}</script>表示马尔可夫链在时刻i的状态:</p>
<script type="math/tex; mode=display">
x^{(i)} = (x_1^{(i)},x_2^{(i)},\dots,x_k^{(i)})^{\top} \ , i=1,2,\dots,n</script><p>其中<script type="math/tex">x_j^{(i)}</script>是随机变量<script type="math/tex">x^{(i)}</script>的第j个分量，j=1,2,…,k。</p>
<p><strong>单分量Metropolis-Hastings算法由下面的k步迭代实现Metropolis-Hastings算法的一次迭代</strong>：</p>
<p>设在第(i-1)次迭代结束时分量<script type="math/tex">x_j</script>的取值为<script type="math/tex">x_j^{(i-1)}</script>，在第i次迭代的第j步，对分量<script type="math/tex">x_j</script>根据Metropolis-Hastings算法更新，得到其新的取值<script type="math/tex">x_j^{(i)}</script>。</p>
<p>首先，由建议分布<script type="math/tex">q(x_j^{(i-1)},x_j|x_{-j}^{(i)})</script>抽样产生分量<script type="math/tex">x_j</script>的候选值<script type="math/tex">x_j^{'(i)}</script>，这里<script type="math/tex">x_{-j}^{(i)}</script>表示在第i次迭代的第(j-1)步后的<script type="math/tex">x^{(i)}</script>除去<script type="math/tex">x_j^{(i-1)}</script>的所有值，即：</p>
<script type="math/tex; mode=display">
x_{-j}^{(i)} = (x_1^{(i)},\dots,x_{j-1}^{(i)},x_{j+1}^{(i-1)},\dots,x_k^{(i-1)})^{\top}</script><p>其中分量1,2,…,j-1已经更新。</p>
<p>然后，按照接受概率：</p>
<script type="math/tex; mode=display">
\alpha(x_j^{(i-1)},x_j^{'(i)}|x_{-j}^{(i)}) = \min \left\{1,\frac{p(x^{'(i)}_j|x_{-j}^{(i)})q(x^{'(i)}_j,x_j^{(i-1)}|x_{-j}^{(i)})}{p(x^{(i-1)}_j|x_{-j}^{(i)})q(x^{(i-1)}_j,x_j^{'(i)}|x_{-j}^{(i)})}\right\}\tag{19-47}</script><p>抽样决定是否接受候选值<script type="math/tex">x_j^{'(i)}</script>。如果<script type="math/tex">x_j^{'(i)}</script>被接受，则令<script type="math/tex">x_j^{(i)}=x_j^{'(i)}</script>；否则令<script type="math/tex">x_j^{(i)}=x_j^{(i-1)}</script>。其余分量在第j步不改变。马尔可夫链的转移概率为：</p>
<script type="math/tex; mode=display">
p(x^{(i-1)}_j,x_j^{'(i)}|x_{-j}^{(i)}) =\alpha(x_j^{(i-1)},x_j^{'(i)}|x_{-j}^{(i)}) q(x^{(i-1)}_j,x_j^{'(i)}|x_{-j}^{(i)}) \tag{19-48}</script><p>下图显示了单分量Metropolis-Hastings算法的迭代过程：</p>
<p><img src="image/19-2.png" alt="19-2"></p>
<p>目标是对二元随机变量x进行抽样。如果变量<script type="math/tex">x_1</script>或<script type="math/tex">x_2</script>更新，那么在水平或垂直方向上产生一个移动，连续水平和垂直移动产生一个新的样本点。</p>
<blockquote>
<p><strong>注意：</strong>由于建议分布可能不被接受，Metropolis-Hastings算法可能在一些相邻的时刻不产生移动。</p>
</blockquote>
<h2 id="吉布斯抽样-Gibbs-sampling"><a href="#吉布斯抽样-Gibbs-sampling" class="headerlink" title="吉布斯抽样(Gibbs sampling)"></a>吉布斯抽样(Gibbs sampling)</h2><p>吉布斯抽样可认为是Metropolis-Hastings算法的特殊情况，更容易实现，且被广泛使用。</p>
<h3 id="基本原理-1"><a href="#基本原理-1" class="headerlink" title="基本原理"></a>基本原理</h3><p>吉布斯抽样(Gibbs sampling)用于多元变量联合分布的抽样和估计。其基本做法是，<strong>从联合概率分布定义满条件概率分布，依次对满条件概率分布进行抽样，得到样本的序列</strong>。(这样的抽样过程是在一个马尔可夫链上的随机游走，每一个样本对应着马尔可夫链的状态，平稳分布就是目标的联合分布)。整体成为一个马尔可夫链蒙特卡罗法，<strong>燃烧期之后的样本就是联合分布的随机样本</strong>。</p>
<p>假设多元变量的联合概率分布为<script type="math/tex">p(x)=p(x_1,x_2,\dots,x_k)</script>。吉布斯抽样从一个初始样本<script type="math/tex">x^{(0)} = (x_1^{(0)},x_2^{(0)},\dots,x_k^{(0)})^{\top}</script>出发，不断进行迭代，每一次迭代得到联合分布的一个样本<script type="math/tex">x^{(i)} = (x_1^{(i)},x_2^{(i)},\dots,x_k^{(i)})^{\top}</script>。最终得到样本序列<script type="math/tex">\{x^{(0)},x^{(1)},\dots,x^{(n)}\}</script>。</p>
<p>在每次迭代中，依次对k个随机变量中的一个变量进行随机抽样。</p>
<p>如果在第i次迭代中，对第j个变量进行随机抽样，那么抽样的分布是满条件概率分布<script type="math/tex">p(x_j|x_{-j}^{(i)})</script>，这里<script type="math/tex">x_{-j}^{(i)}</script>表示第i次迭代中，变量j以外的其它变量。</p>
<p>设在第(i-1)步得到样本<script type="math/tex">(x_1^{(i-1)},x_2^{(i-1)},\dots,x_k^{(i-1)})^{\top}</script>，在第i步，首先对第一个变量按照以下满条件概率分布随机抽样：</p>
<script type="math/tex; mode=display">
p(x_1|x_2^{(t-1)},\dots,x_k^{(t-1)})</script><p>得到<script type="math/tex">x_1^{(i)}</script>，之后依次对第j个变量按照以下满条件概率分布随机抽样：</p>
<script type="math/tex; mode=display">
p(x_j|x_1^{(i)},\dots,x_{j-1}^{(i)},x_{j+1}^{(i-1)},\dots,x_k^{(i-1)}) \ , j=2,\dots,k-1</script><p>得到<script type="math/tex">x_j^{(i)}</script>，最后对第k个变量按照以下满条件概率分布随机抽样：</p>
<script type="math/tex; mode=display">
p(x_k|x_1^{(i)},\dots,x_k^{(i)})</script><p>得到<script type="math/tex">x_j^{(i)}</script>，于是得到整体样本<script type="math/tex">x^{(i)} = (x_1^{(i)},x_2^{(i)},\dots,x_k^{(i)})^{\top}</script>。</p>
<p><strong>吉布斯抽样是单分量Metropolis-Hastings算法的特殊情况</strong>。</p>
<p>定义建议分布是当前变量<script type="math/tex">x_j</script>，j=1,2,…,k的满条件概率分布:</p>
<script type="math/tex; mode=display">
q(x,x^{'}) = p(x_j^{'}|x_{-j}) \tag{19-49}</script><p>这时，接受概率<script type="math/tex">\alpha=1</script>，</p>
<script type="math/tex; mode=display">
\begin{aligned}
\alpha(x,x^{'})& = \min \left\{1,\frac{p(x^{'})q(x^{'},x)}{p(x)q(x,x^{'})}\right\}\\
& = \min \left\{1,\frac{p(x^{'}_{-j})p(x_j^{'}|x_{-j}^{'})p(x_j|x_{-j}^{'})}{p(x_{-j})p(x_j|x_{-j})p(x_j|x_{-j}^{'})}\right\}\\
&= 1
\end{aligned} \tag{19-50}</script><p>这里用到<script type="math/tex">p(x_{-j})=p(x^{'}_{-j})</script> 和<script type="math/tex">p(\bullet|x_{-j})=p(\bullet|x^{'}_{-j})</script>。</p>
<p><strong>转移核就是满条件概率分布</strong>：</p>
<script type="math/tex; mode=display">
p(x,x^{'}) = p(x^{'}_j|x_{-j}) \tag{19-51}</script><p>也就是说，依次按照单变量的满条件概率分布<script type="math/tex">p(x^{'}_j|x_{-j})</script>进行随机抽样，就能实现单分量Metropolis-Hastings算法。<strong>吉布斯抽样对每次抽样的结果都接受，没有拒绝，这一点和一般的Metropolis-Hastings算法不同</strong>。</p>
<blockquote>
<p>这里，假设满条件概率分布<script type="math/tex">p(x^{'}_j|x_{-j})</script>不为0，即马尔可夫链是不可约的。</p>
</blockquote>
<h3 id="吉布斯抽样算法"><a href="#吉布斯抽样算法" class="headerlink" title="吉布斯抽样算法"></a>吉布斯抽样算法</h3><p><strong>算法19.3(吉布斯抽样)</strong></p>
<p>输入：目标概率分布的密度函数p(x)，函数f(x)</p>
<p>输出：p(x)的随机样本<script type="math/tex">x_{m+1},x_{m+2},\dots,x_n</script>，函数样本均值<script type="math/tex">f_{mn}</script>；</p>
<p>参数：收敛步数m，迭代步数n。</p>
<ol>
<li><p>初始化。给出初始样本<script type="math/tex">x^{(0)} = (x_1^{(0)},x_2^{(0)},\dots,x_k^{(0)})^{\top}</script>。</p>
</li>
<li><p>对i循环执行</p>
<p>设第i-1次迭代结束时的样本为<script type="math/tex">(x_1^{(i-1)},x_2^{(i-1)},\dots,x_k^{(i-1)})^{\top}</script>，则第i次迭代进行如下几步操作：</p>
<p>(1)由满条件分布<script type="math/tex">p(x_1|x_2^{(i-1)},\dots,x_k^{(i-1)})</script>抽取<script type="math/tex">x_1^{(i)}</script></p>
<script type="math/tex; mode=display">\vdots</script><p>(j)由满条件分布<script type="math/tex">p(x_j|x_1^{(i)},\dots,x_{j-1}^{(i)},x_{j+1}^{(i-1)},\dots,x_k^{(i-1)}) \ , j=2,\dots,k-1</script>抽取<script type="math/tex">x_j^{(i)}</script></p>
<script type="math/tex; mode=display">\vdots</script><p>(k)由满条件分布<script type="math/tex">p(x_k|x_1^{(i)},\dots,x_k^{(i)})</script>抽取<script type="math/tex">x_k^{(i)}</script></p>
<p>得到第i次迭代值<script type="math/tex">x^{(i)} = (x_1^{(i)},x_2^{(i)},\dots,x_k^{(i)})^{\top}</script>。</p>
</li>
<li><p>得到 样本集合<script type="math/tex">x_{m+1},x_{m+2},\dots,x_n</script></p>
</li>
<li><p>计算</p>
<script type="math/tex; mode=display">
f_{mn} = \frac{1}{n-m}\sum_{i=m+1}^n f(x_i)</script></li>
</ol>
<h3 id="抽样计算"><a href="#抽样计算" class="headerlink" title="抽样计算"></a>抽样计算</h3><p>以贝叶斯学习为例介绍吉布斯抽样这个技巧。</p>
<p>设y表示观测数据,<script type="math/tex">\alpha,\theta,z</script>分别表示超参数、模型参数、未观测数据，<script type="math/tex">x=(\alpha,\theta,z)</script>，它们的依赖关系如下图所示：</p>
<p><img src="image/19-3.png" alt="19-3"></p>
<p>贝叶斯学习的目的是估计后验概率分布<script type="math/tex">p(x|y)</script>，求后验概率最大的模型。</p>
<script type="math/tex; mode=display">
p(x|y) = p(\alpha,\theta,z|y) \propto p(z,y|\theta)p(\theta|\alpha)p(\alpha) \tag{19-52}</script><p>式中<script type="math/tex">p(\alpha)</script>是超参数分布,<script type="math/tex">p(\theta|\alpha)</script>是先验分布，<script type="math/tex">p(z,y|\theta)</script>是完全数据的分布。</p>
<p>现在用吉布斯抽样估计<script type="math/tex">p(x|y)</script>，其中y已知,<script type="math/tex">x=(\alpha,\theta,z)</script>未知。吉布斯抽样中各个变量<script type="math/tex">\alpha,\theta,z</script>的满条件分布有以下关系：</p>
<script type="math/tex; mode=display">
p(\alpha_i|\alpha_{-i},\theta,z,y) \propto p(\theta|\alpha)p(\alpha) \tag{19-53}</script><script type="math/tex; mode=display">
p(\theta_j|\theta_{-j},\alpha,z,y) \propto p(z,y|\theta)p(\theta|\alpha) \tag{19-54}</script><script type="math/tex; mode=display">
p(z_k|z_{-k},\alpha,\theta,y) \propto p(z,y|\theta) \tag{19-55}</script><p>其中<script type="math/tex">\alpha_{-i}</script>表示变量<script type="math/tex">\alpha_i</script>以外的所有变量,<script type="math/tex">\theta_{-j}</script>和<script type="math/tex">z_{-k}</script>类似。</p>
<p>满条件概率分布于若干条件概率分布的乘积成正比，各个条件概率分布只由少量的相关变量组成(图模型中相邻结点表示的变量)。</p>
<p>所以，依满条件概率分布的抽样可以通过依这些条件概率分布的乘积的抽样进行。这样可以大幅减少抽样的计算复杂度，因为计算只涉及部分变量。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ul>
<li><a href="https://www.cs.ubc.ca/~arnaud/andrieu_defreitas_doucet_jordan_intromontecarlomachinelearning.pdf" target="_blank" rel="noopener">An Introduction to MCMC for Machine Learning</a></li>
<li></li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/无监督学习/" rel="tag"># 无监督学习</a>
          
            <a href="/tags/MCMC/" rel="tag"># MCMC</a>
          
            <a href="/tags/马尔可夫链蒙特卡罗法/" rel="tag"># 马尔可夫链蒙特卡罗法</a>
          
            <a href="/tags/吉布斯抽样/" rel="tag"># 吉布斯抽样</a>
          
            <a href="/tags/Gibbs-Sampling/" rel="tag"># Gibbs Sampling</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/09/01/plsa/" rel="next" title="概率潜在语义分析">
                <i class="fa fa-chevron-left"></i> 概率潜在语义分析
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/09/06/LDA/" rel="prev" title="潜在狄利克雷分布LDA">
                潜在狄利克雷分布LDA <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">jozee</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">83</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#蒙特卡罗法"><span class="nav-number">1.</span> <span class="nav-text">蒙特卡罗法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#随机抽样"><span class="nav-number">1.1.</span> <span class="nav-text">随机抽样</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数学期望估计"><span class="nav-number">1.2.</span> <span class="nav-text">数学期望估计</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#积分计算"><span class="nav-number">1.3.</span> <span class="nav-text">积分计算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#马尔可夫链"><span class="nav-number">2.</span> <span class="nav-text">马尔可夫链</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本定义"><span class="nav-number">2.1.</span> <span class="nav-text">基本定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#离散状态马尔可夫链"><span class="nav-number">2.2.</span> <span class="nav-text">离散状态马尔可夫链</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#转移概率矩阵和状态分布"><span class="nav-number">2.2.1.</span> <span class="nav-text">转移概率矩阵和状态分布</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#平稳分布"><span class="nav-number">2.2.2.</span> <span class="nav-text">平稳分布</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#连续状态马尔可夫链"><span class="nav-number">2.3.</span> <span class="nav-text">连续状态马尔可夫链</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#马尔可夫链的性质"><span class="nav-number">2.4.</span> <span class="nav-text">马尔可夫链的性质</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#不可约"><span class="nav-number">2.4.1.</span> <span class="nav-text">不可约</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#非周期"><span class="nav-number">2.4.2.</span> <span class="nav-text">非周期</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#正常返-positive-recurrent"><span class="nav-number">2.4.3.</span> <span class="nav-text">正常返(positive recurrent)</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#遍历定理"><span class="nav-number">2.4.4.</span> <span class="nav-text">遍历定理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#可逆马尔可夫链"><span class="nav-number">2.4.5.</span> <span class="nav-text">可逆马尔可夫链</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#马尔可夫链蒙特卡罗法"><span class="nav-number">3.</span> <span class="nav-text">马尔可夫链蒙特卡罗法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本想法"><span class="nav-number">3.1.</span> <span class="nav-text">基本想法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#基本步骤"><span class="nav-number">3.2.</span> <span class="nav-text">基本步骤</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#马尔可夫链蒙特卡罗法与统计学习"><span class="nav-number">3.3.</span> <span class="nav-text">马尔可夫链蒙特卡罗法与统计学习</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Metropolis-Hastings算法"><span class="nav-number">4.</span> <span class="nav-text">Metropolis-Hastings算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本原理"><span class="nav-number">4.1.</span> <span class="nav-text">基本原理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#马尔可夫链-1"><span class="nav-number">4.1.1.</span> <span class="nav-text">马尔可夫链</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#建议分布"><span class="nav-number">4.1.1.1.</span> <span class="nav-text">建议分布</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#满条件分布"><span class="nav-number">4.1.2.</span> <span class="nav-text">满条件分布</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Metropolis-Hastings算法-1"><span class="nav-number">4.2.</span> <span class="nav-text">Metropolis-Hastings算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#单分量Metropolis-Hastings算法"><span class="nav-number">4.3.</span> <span class="nav-text">单分量Metropolis-Hastings算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#吉布斯抽样-Gibbs-sampling"><span class="nav-number">5.</span> <span class="nav-text">吉布斯抽样(Gibbs sampling)</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本原理-1"><span class="nav-number">5.1.</span> <span class="nav-text">基本原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#吉布斯抽样算法"><span class="nav-number">5.2.</span> <span class="nav-text">吉布斯抽样算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#抽样计算"><span class="nav-number">5.3.</span> <span class="nav-text">抽样计算</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#参考资料"><span class="nav-number">6.</span> <span class="nav-text">参考资料</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jozee</span>

  
</div>
<div class="busuanzi_count">
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
    </script>
    <span> 本站访客数:<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
    <span>本站总访问量:<span id="busuanzi_value_site_pv"></span>次</span>
</div>









        






        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://jozeelin.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://jozeelin.github.io/2019/09/06/mcmc/';
          this.page.identifier = '2019/09/06/mcmc/';
          this.page.title = '马尔可夫链蒙特卡罗法';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://jozeelin.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
