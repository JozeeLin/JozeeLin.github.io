<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">



  <meta name="google-site-verification" content="iejSa-LmOb9d1GguAcEsQNUsQviccOieHkuG1c1E2YI">



  <meta name="msvalidate.01" content="83768A52AE58ADF203609FEF9C55FF47">












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="无监督学习,PCA,降维算法,">










<meta name="description" content="主成分分析(PCA)是一种常用的无监督学习方法，这一方法利用正交变换把由线性相关变量表示的观测数据转换为少数几个由线性无关变量表示的数据，线性无关的变量称为主成分。 主成分的个数通常小于原始变量的个数，所以主成分分析属于降维方法。 主成分分析主要用于发现数据中的基本结构，即数据中变量之间的关系。 总体主成分分析基本想法主成分分析中，  首先对给定数据进行规范化，使得数据每一变量的平均值为0，方差为">
<meta name="keywords" content="无监督学习,PCA,降维算法">
<meta property="og:type" content="article">
<meta property="og:title" content="PCA主成分分析">
<meta property="og:url" content="https://jozeelin.github.io/2019/08/28/pca/index.html">
<meta property="og:site_name" content="Jozee&#39;s技术博客">
<meta property="og:description" content="主成分分析(PCA)是一种常用的无监督学习方法，这一方法利用正交变换把由线性相关变量表示的观测数据转换为少数几个由线性无关变量表示的数据，线性无关的变量称为主成分。 主成分的个数通常小于原始变量的个数，所以主成分分析属于降维方法。 主成分分析主要用于发现数据中的基本结构，即数据中变量之间的关系。 总体主成分分析基本想法主成分分析中，  首先对给定数据进行规范化，使得数据每一变量的平均值为0，方差为">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://jozeelin.github.io/2019/08/28/pca/image/16-1.png">
<meta property="og:image" content="https://jozeelin.github.io/2019/08/28/pca/image/16-2.png">
<meta property="og:updated_time" content="2019-08-28T13:00:32.292Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PCA主成分分析">
<meta name="twitter:description" content="主成分分析(PCA)是一种常用的无监督学习方法，这一方法利用正交变换把由线性相关变量表示的观测数据转换为少数几个由线性无关变量表示的数据，线性无关的变量称为主成分。 主成分的个数通常小于原始变量的个数，所以主成分分析属于降维方法。 主成分分析主要用于发现数据中的基本结构，即数据中变量之间的关系。 总体主成分分析基本想法主成分分析中，  首先对给定数据进行规范化，使得数据每一变量的平均值为0，方差为">
<meta name="twitter:image" content="https://jozeelin.github.io/2019/08/28/pca/image/16-1.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://jozeelin.github.io/2019/08/28/pca/">





  <title>PCA主成分分析 | Jozee's技术博客</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Jozee's技术博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://jozeelin.github.io/2019/08/28/pca/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="jozee">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Jozee's技术博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">PCA主成分分析</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-08-28T20:48:46+08:00">
                2019-08-28
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2019-08-28T21:00:32+08:00">
                2019-08-28
              </time>
            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2019/08/28/pca/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count" data-disqus-identifier="2019/08/28/pca/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
          <span id="busuanzi_container_page_pv">
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon">
            <i class="fa fa-eye"></i>
            </span>
            阅读量: <span id="busuanzi_value_page_pv"></span>次
          </span>
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>主成分分析(PCA)是一种常用的无监督学习方法，这一方法<strong>利用正交变换</strong>把<strong>由线性相关变量表示的观测数据</strong>转换为少数几个<strong>由线性无关变量表示的数据</strong>，<strong>线性无关的变量称为主成分</strong>。</p>
<p>主成分的个数通常小于原始变量的个数，所以主成分分析属于降维方法。</p>
<p>主成分分析<strong>主要用于发现数据中的基本结构</strong>，即数据中<strong>变量之间的关系</strong>。</p>
<h2 id="总体主成分分析"><a href="#总体主成分分析" class="headerlink" title="总体主成分分析"></a>总体主成分分析</h2><h3 id="基本想法"><a href="#基本想法" class="headerlink" title="基本想法"></a>基本想法</h3><p>主成分分析中，</p>
<ol>
<li><p>首先对给定数据进行规范化，使得数据每一变量的平均值为0，方差为1</p>
</li>
<li><p>对数据进行正交变换。原来由线性相关变量表示的数据，通过正交变换变成由若干个线性无关的新变量表示的数据。<strong>新变量是可能的正交变换中变量的方差的和(信息保存)最大的，方差表示在新变量上的信息的大小</strong>。</p>
<p>将新变量依次称为第一主成分、第二主成分等。</p>
</li>
</ol>
<p>通过主成分分析，可以利用主成分近似地表示原始数据(可理解为发现数据的基本结构)，也可以把数据由少数主成分表示(这可理解为对数据降维)。</p>
<blockquote>
<p>数据集合中的样本由实数空间(正交坐标系)中的点表示，空间的一个坐标轴表示一个变量，<strong>规范化处理后得到的数据分布在原点附近</strong>。对原坐标系中的数据进行主成分分析等价于进行坐标系旋转变换，将数据投影到新坐标系的坐标轴上；新坐标系的第一坐标轴、第二坐标轴等分别表示第一主成分、第二主成分等。<strong>数据在每一轴上的坐标值的平方表示相应变量的方差；并且，这个坐标系是在所有可能的新的坐标系中，坐标轴上的方差的和最大的</strong>。</p>
</blockquote>
<p>如下图所示，原坐标系<script type="math/tex">(X_1,X_2)</script>，进行正交变换后新坐标系<script type="math/tex">(Y_1,Y_2)</script>：</p>
<p><img src="image/16-1.png" alt="16-1"></p>
<p>接下来，看看方差最大的解释：</p>
<p>假设有两个变量<script type="math/tex">X_1,X_2</script>，三个样本点A,B,C，样本分布在由<script type="math/tex">X_1,X_2</script>轴组成的坐标系中，如下图所示：</p>
<p><img src="image/16-2.png" alt="16-1"></p>
<p>对坐标系进行旋转变换，得到新的坐标轴<script type="math/tex">Y_1</script>，表示新的变量<script type="math/tex">Y_1</script>。样本点A,B,C在<script type="math/tex">Y_1</script>轴上投影，得到<script type="math/tex">Y_1</script>轴的坐标值<script type="math/tex">A^{'},B^{'},C^{'}</script>。坐标值的平方和<script type="math/tex">OA^{'2}+OB^{'2}+OC^{'2}</script>表示样本在变量<script type="math/tex">y_1</script>上的方差。</p>
<p><strong>主成分分析旨在选取正交变换中方差最大的变量，作为第一主成分，也就是旋转变换中的坐标值的平方和最大的轴</strong>。</p>
<p><strong>如何确保平方和最大？</strong>首先旋转变换中样本点到原点的距离的平方和<script type="math/tex">OA^2+OB^2+OC^2</script>保持不变，根据勾股定理，新坐标值的平方和<script type="math/tex">OA^{'2}+OB^{'2}+OC^{'2}</script>最大等价于样本点到<script type="math/tex">Y_1</script>轴的距离的平方和<script type="math/tex">AA^{'2}+BB^{'2}+CC^{'2}</script>最小。也就是说，<strong>主成分分析在旋转变换中选取离样本点的距离平方和最小的轴，作为第一主成分</strong>。</p>
<p>第二主成分等的选取，在保证与已选新坐标轴(已选主成分)正交的条件下，类似的进行。</p>
<blockquote>
<p>在数据总体上进行主成分分析称为<strong>总体主成分分析</strong>。</p>
<p>在有限样本上进行主成分分析称为<strong>样本主成分分析</strong>。</p>
</blockquote>
<h3 id="定义和导出"><a href="#定义和导出" class="headerlink" title="定义和导出"></a>定义和导出</h3><p>假设<script type="math/tex">\boldsymbol{x} = (x_1,x_2,\dots,x_m)^{\top}</script>是m维随机变量，其均值向量是<script type="math/tex">\boldsymbol{\mu}</script></p>
<script type="math/tex; mode=display">
\boldsymbol{\mu} = E(\boldsymbol{x}) = (\mu_1,\mu_2,\dots,\mu_m)^{\top}</script><p>协方差矩阵是<script type="math/tex">\Sigma</script></p>
<script type="math/tex; mode=display">
\Sigma = \mathrm{cov}(\boldsymbol{x},\boldsymbol{x}) = E[(\boldsymbol{x}-\boldsymbol{\mu})(\boldsymbol{x}-\boldsymbol{\mu})^{\top}]</script><p>考虑由m维随机变量<script type="math/tex">\boldsymbol{x}</script> 到m维随机变量<script type="math/tex">\boldsymbol{y}=(y_1,y_2,\dots,y_m)^{\top}</script>的线性变换：</p>
<script type="math/tex; mode=display">
y_i = \alpha_i^{\top}\boldsymbol{x} = \alpha_{1i}x_1+\alpha_{2i}x_2+\dots+\alpha_{mi}x_m \tag{16-1}</script><p>其中<script type="math/tex">\alpha_i^{\top} = (\alpha_{1i},\alpha_{2i},\dots,\alpha_{mi}) \ , i=1,2,\dots,m</script>。</p>
<p>由随机变量的性质可知：</p>
<script type="math/tex; mode=display">
E(y_i) = \alpha_i^{\top}\boldsymbol{\mu} \ , i=1,2,\dots,m \tag{16-2}</script><script type="math/tex; mode=display">
\mathrm{var}(y_i) = \alpha_i^{\top} \Sigma \alpha_i \ , i=1,2,\dots,m \tag{16-3}</script><script type="math/tex; mode=display">
\mathrm{cov}(y_i,y_j)= \alpha_i^{\top} \Sigma \alpha_j \ , i=1,2,\dots,m\ ; j=1,2,\dots,m \tag{16-4}</script><p><strong>定义16.1(总体主成分)</strong> 给定一个如式(16-1)所示的线性变换，如果它们满足下列条件</p>
<ol>
<li><p>系数向量<script type="math/tex">\alpha_i^{\top}</script>是单位向量，即<script type="math/tex">\alpha_i^{\top}\alpha_i=1 \ , i=1,2,\dots,m</script></p>
</li>
<li><p>变量<script type="math/tex">y_i</script>与<script type="math/tex">y_j</script> 互不相关，即<script type="math/tex">\mathrm{cov}(y_i,y_j)=0 \ (i\ne j)</script></p>
</li>
<li><p>变量<script type="math/tex">y_1</script>是<script type="math/tex">\boldsymbol{x}</script>的所有线性变换中方差最大的；<script type="math/tex">y_2</script>是与<script type="math/tex">y_1</script>不相关的<script type="math/tex">\boldsymbol{x}</script>的所有线性变换中方差最大的；一般地，<script type="math/tex">y_i</script>是与<script type="math/tex">y_1,y_2,\dots,y_{i-1} \ (i=1,2,\dots,m)</script>都不相关的<script type="math/tex">\boldsymbol{x}</script>的所有线性变换中方差最大的；</p>
<p>这时分别称<script type="math/tex">y_1,y_2,\dots,y_{m} \ (i=1,2,\dots,m)</script>为<script type="math/tex">\boldsymbol{x}</script>的第一主成分、第二主成分、…、第m主成分。</p>
</li>
</ol>
<p>定义中的条件1表明线性变换是正交变换，<script type="math/tex">\alpha_1,\alpha_2,\dots,\alpha_m</script>是一组标准正交基，</p>
<script type="math/tex; mode=display">
\alpha_i^{\top}\alpha_j = \left\{\begin{aligned}&1,i=j\\&0,i\ne j\end{aligned} \right.</script><p>条件2，3给出了一个求主成分的方法：</p>
<p>第一步：在<script type="math/tex">\boldsymbol{x}</script>的所有线性变换</p>
<script type="math/tex; mode=display">
\alpha_1^{\top}\boldsymbol{x} = \sum_{i=1}^m \alpha_{i1}x_i</script><p>中，在<script type="math/tex">\alpha_1^{\top}\alpha_1=1</script>条件下，求方差最大的，得到<script type="math/tex">\boldsymbol{x}</script>的第一主成分；</p>
<p>第二步，在与<script type="math/tex">\alpha_1^{\top}\boldsymbol{x}</script>不相关的<script type="math/tex">\boldsymbol{x}</script>的所有线性变换：</p>
<script type="math/tex; mode=display">
\alpha_2^{\top}\boldsymbol{x} = \sum_{i=1}^m \alpha_{i2}x_i</script><p>中，在 <script type="math/tex">\alpha_2^{\top}\alpha_2=1</script>条件下，求方差最大的，得到<script type="math/tex">\boldsymbol{x}</script>的第二主成分；</p>
<p>第k步，在于<script type="math/tex">\alpha_1^{\top}\boldsymbol{x},\alpha_2^{\top}\boldsymbol{x},\dots,\alpha_{k-1}^{\top}\boldsymbol{x}</script>不相关的<script type="math/tex">\boldsymbol{x}</script>的所有线性变换：</p>
<script type="math/tex; mode=display">
\alpha_k^{\top}\boldsymbol{x} = \sum_{i=1}^m \alpha_{ik}x_i</script><p>中，在<script type="math/tex">\alpha_k^{\top}\alpha_k=1</script>条件下，求方差最大的，得到<script type="math/tex">\boldsymbol{x}</script>的第k主成分；</p>
<p>如此继续下去，直到得到<script type="math/tex">\boldsymbol{x}</script>的第m主成分。</p>
<h3 id="主要性质"><a href="#主要性质" class="headerlink" title="主要性质"></a>主要性质</h3><p><strong>定理16.1</strong> 设<script type="math/tex">\boldsymbol{x}</script>是m维随机变量，<script type="math/tex">\Sigma</script>是<script type="math/tex">\boldsymbol{x}</script>的协方差矩阵，<script type="math/tex">\Sigma</script>的特征值分别是<script type="math/tex">\lambda_1\ge\lambda_2\ge \dots \ge \lambda_m \ge 0</script>，特征值对应的单位特征向量分别是<script type="math/tex">\alpha_1,\alpha_2,\dots,\alpha_m</script>，则<script type="math/tex">\boldsymbol{x}</script>的第k主成分是:</p>
<script type="math/tex; mode=display">
y_k = \alpha_k^{\top}\boldsymbol{x} = \alpha_{1k}x_1+\alpha_{2k}x_2+\dots+\alpha_{mk}x_m \ ,\ k=1,2,\dots,m \tag{16-5}</script><p>关于<script type="math/tex">\boldsymbol{x}</script>的第k主成分的方差是:</p>
<script type="math/tex; mode=display">
\mathrm{var}(y_k) = \alpha_k^{\top}\Sigma \alpha_k = \lambda_k \ , \ k=1,2,\dots,m \tag{16-6}</script><p>即协方差矩阵<script type="math/tex">\Sigma</script>的第k个特征值。</p>
<blockquote>
<p>若特征值有重根，对应的特征向量组成m维空间<script type="math/tex">R^m</script>的一个子空间，子空间的维数等于重根数，在子空间任取一个正交坐标系，这个坐标系的单位向量就可作为特征向量。这是坐标系取法不唯一。</p>
</blockquote>
<p><strong>证明</strong>：采用拉格朗日乘子法求出主成分。</p>
<p><strong>首先，求<script type="math/tex">\boldsymbol{x}</script>的第一主成分<script type="math/tex">y_1=\alpha_1^{\top}\boldsymbol{x}</script></strong>，</p>
<p>即求系数向量<script type="math/tex">\alpha_1</script>。由定义16.1知，第一主成分的<script type="math/tex">\alpha_1</script>是在<script type="math/tex">\alpha_1^{\top}\alpha_1=1</script>条件下，<script type="math/tex">\boldsymbol{x}</script>的所有线性变换中使方差：</p>
<script type="math/tex; mode=display">
\mathrm{var}(\alpha_1^{\top}\boldsymbol{x}) = \alpha_1^{\top}\Sigma \alpha_1</script><p>达到最大的。</p>
<p><strong>求第一主成分就是求解约束最优化问题</strong>：</p>
<script type="math/tex; mode=display">
\max_{\alpha_1} \alpha_1^{\top}\Sigma \alpha_1 \tag{16-7}</script><p>s.t.</p>
<script type="math/tex; mode=display">
\alpha_1^{\top}\alpha_1 = 1</script><p>定义拉格朗日函数</p>
<script type="math/tex; mode=display">
\alpha_1^{\top}\Sigma \alpha_1 -\lambda(\alpha_1^{\top}\alpha_1-1)</script><p>其中<script type="math/tex">\lambda</script>为拉格朗日乘子。将拉格朗日函数对<script type="math/tex">\alpha_1</script>进行求导，并令其为0，得：</p>
<script type="math/tex; mode=display">
\Sigma \alpha_1 - \lambda \alpha_1 = 0</script><p>因此，<script type="math/tex">\lambda</script>是<script type="math/tex">\Sigma</script>得特征值，<script type="math/tex">\alpha_1</script>是对应的单位特征向量。于是，目标函数：</p>
<script type="math/tex; mode=display">
\alpha_1^{\top}\Sigma \alpha_1 = \alpha_1^{\top}\lambda \alpha_1 = \lambda \alpha_1^{\top}\alpha_1 = \lambda</script><p>假设<script type="math/tex">\alpha_1</script>是<script type="math/tex">\Sigma</script>的最大特征值<script type="math/tex">\lambda_1</script>对应的单位特征向量，显然<script type="math/tex">\alpha_1</script>与<script type="math/tex">\lambda_1</script>是最优化问题的解。</p>
<p>所以，<script type="math/tex">\alpha_1^{\top}\boldsymbol{x}</script>构成第一主成分，其方差等于协方差矩阵的最大特征值:</p>
<script type="math/tex; mode=display">
\mathrm{var}(\alpha_1^{\top}\boldsymbol{x}) = \alpha_1^{\top}\Sigma \alpha_1 = \lambda_1 \tag{16-8}</script><p><strong>接着，求<script type="math/tex">\boldsymbol{x}</script>的第二主成分<script type="math/tex">y_2 = \alpha_2^{\top}\boldsymbol{x}</script></strong>，</p>
<p>第二主成分的<script type="math/tex">\alpha_2</script>是在<script type="math/tex">\alpha_2^{\top}\alpha_2=1</script>，且<script type="math/tex">\alpha_2^{\top}\boldsymbol{x}</script>与<script type="math/tex">\alpha_1^{\top}\boldsymbol{x}</script>不相关的条件下(也就是说<script type="math/tex">\alpha_2^{\top}\boldsymbol{x}</script>与<script type="math/tex">\alpha_1^{\top}\boldsymbol{x}</script>的协方差为0，协方差公式(16-4))，<script type="math/tex">\boldsymbol{x}</script>的所有线性变换中使方差：</p>
<script type="math/tex; mode=display">
\mathrm{var}(\alpha_2^{\top}\boldsymbol{x}) = \alpha_2^{\top}\Sigma \alpha_2</script><p>达到最大的。</p>
<p><strong>求第二主成分需要求解约束最优化问题</strong>:</p>
<script type="math/tex; mode=display">
\max_{\alpha_2} = \alpha_2^{\top} \Sigma \alpha_2 \tag{16-9}</script><p>s.t.</p>
<script type="math/tex; mode=display">
\alpha_1^{\top}\Sigma \alpha_2 = 0,\alpha_2^{\top}\Sigma\alpha_1 = 0,\alpha_2^{\top}\alpha_2=1</script><p>注意到</p>
<script type="math/tex; mode=display">
\alpha_1^{\top}\Sigma \alpha_2 = \alpha_2^{\top}\Sigma \alpha_1 = \alpha_2^{\top}\lambda_1\alpha_1 = \lambda_1 \alpha_2^{\top}\alpha_1=\lambda_1\alpha_1^{\top}\alpha_2</script><p>以及</p>
<script type="math/tex; mode=display">
\alpha_1^{\top}\alpha_2 = 0 , \alpha_2^{\top}\alpha_1 = 0</script><p>定义拉格朗日函数</p>
<script type="math/tex; mode=display">
\alpha_2^{\top}\Sigma \alpha_2 - \lambda(\alpha_2^{\top}\alpha_2-1)-\phi\alpha_2^{\top}\alpha_1</script><p>其中<script type="math/tex">\lambda</script>，<script type="math/tex">\phi</script>是拉格朗日乘子。对<script type="math/tex">\alpha_2</script>求导，并令其为0，得:</p>
<script type="math/tex; mode=display">
2\Sigma \alpha_2 - 2\lambda \alpha_2 -\phi \alpha_1 = 0 \tag{16-10}</script><p>将方程左乘以<script type="math/tex">\alpha_1^{\top}</script>有:</p>
<script type="math/tex; mode=display">
2\alpha_1^{\top}\Sigma \alpha_2 - 2\lambda\alpha_1^{\top} \alpha_2 -\phi \alpha_1^{\top}\alpha_1 = 0</script><p>此式前两项为0，且<script type="math/tex">\alpha^{\top}_1\alpha_1 = 1</script>，导出<script type="math/tex">\phi=0</script>，因此式(16-10)成为:</p>
<script type="math/tex; mode=display">
\Sigma \alpha_2 - \lambda \alpha_2 = 0</script><p>由此，<script type="math/tex">\lambda</script>是<script type="math/tex">\Sigma</script>的特征值，<script type="math/tex">\alpha_2</script>是对应的单位特征向量。于是，目标函数：</p>
<script type="math/tex; mode=display">
\alpha_2^{\top}\Sigma \alpha_2 = \alpha_2^{\top} \lambda \alpha_2 = \lambda \alpha_2^{\top}\alpha_2 = \lambda</script><p><strong>假设<script type="math/tex">\alpha_2</script>是<script type="math/tex">\Sigma</script>的第二大特征值<script type="math/tex">\lambda_2</script>对应的单位特征向量，显然<script type="math/tex">\alpha_2</script>与<script type="math/tex">\lambda_2</script>是以上最优化问题的解</strong>。</p>
<p>于是<script type="math/tex">\alpha_2^{\top}\boldsymbol{x}</script>构成第二主成分，其方差等于协方差矩阵的第二大特征，</p>
<script type="math/tex; mode=display">
\mathrm{var}(\alpha_2^{\top}\boldsymbol{x}) = \alpha_2^{\top}\Sigma\alpha_2 = \lambda_2 \tag{16-11}</script><p>一般地，<script type="math/tex">\boldsymbol{x}</script>的第k主成分是<script type="math/tex">\alpha_k^{\top}\boldsymbol{x}</script>，并且<script type="math/tex">\mathrm{var}(\alpha_k^{\top}\boldsymbol{x})=\lambda_k</script>，这里<script type="math/tex">\lambda_k</script>是<script type="math/tex">\Sigma</script>的第k个特征值并且<script type="math/tex">\alpha_k</script>是对应的单位特征向量。</p>
<p>以此类推，第k个主成分的方差等于<script type="math/tex">\Sigma</script>的第k个特征值:</p>
<script type="math/tex; mode=display">
\mathrm{var}(\alpha_k^{\top}\boldsymbol{x}) = \alpha_k^{\top}\Sigma \alpha_k = \lambda_k \ , k=1,2,\dots,m \tag{16-12}</script><p>定理证毕。</p>
<p><strong>推论16.1</strong> m维随机变量<script type="math/tex">\boldsymbol{y} = (y_1,y_2,\dots,y_m)^{\top}</script>的分量依次是<script type="math/tex">\boldsymbol{x}</script> 的第一主成分到第m主成分的充要条件是：</p>
<ol>
<li><p>令<script type="math/tex">\boldsymbol{y} = A^{\top}\boldsymbol{x}</script>，A为正交矩阵</p>
<script type="math/tex; mode=display">
A = \begin{bmatrix}
   \alpha_{11} & \alpha_{12}&\dots&\alpha_{1m} \\
   \alpha_{21}&\alpha_{22}&\dots&\alpha_{2m}\\
   \vdots&\vdots&&\vdots\\
   \alpha_{m1}&\alpha_{m2}&\dots&\alpha_{mm}
\end{bmatrix}</script></li>
<li><p>其中<script type="math/tex">\boldsymbol{y}</script>的协方差矩阵为对角矩阵</p>
<script type="math/tex; mode=display">
\mathrm{cov}(\boldsymbol{y}) = \mathrm{diag}(\lambda_1,\lambda_2,\dots,\lambda_m)</script><script type="math/tex; mode=display">
\lambda_1\ge\lambda_2\ge\dots\ge\lambda_m</script><p>其中<script type="math/tex">\lambda_k</script>是<script type="math/tex">\Sigma</script>的第k个特征值，<script type="math/tex">\alpha_k</script>是对应的单位特征向量，k=1,2,…,m。</p>
</li>
</ol>
<p>以上证明中，<script type="math/tex">\lambda_k</script>是<script type="math/tex">\Sigma</script>的第k个特征值，<script type="math/tex">\alpha_k</script>是对应的单位特征向量，即</p>
<script type="math/tex; mode=display">
\Sigma \alpha_k = \lambda_k \alpha_k \ , k=1,2,\dots,m \tag{16-13}</script><p>用矩阵表示即为:</p>
<script type="math/tex; mode=display">
\Sigma A = A\varLambda \tag{16-14}</script><p>这里<script type="math/tex">A = [\alpha_{ij}]_{m\times m}</script>(注意：这里的A与前面的<script type="math/tex">A\in m\times n</script> 不是同一个！)，<script type="math/tex">\varLambda</script>是对角矩阵，其第k个对角元素是<script type="math/tex">\lambda_k</script>。因为A是正交矩阵，即<script type="math/tex">A^{\top}A = AA^{\top} = I</script>，由式(16-14)得到两个公式:</p>
<script type="math/tex; mode=display">
A^{\top}\Sigma A = \varLambda \tag{16-15}</script><p>和</p>
<script type="math/tex; mode=display">
\Sigma = A\varLambda A^{\top} \tag{16-16}</script><p>下面叙述总体主成分的性质：</p>
<ol>
<li><p>总体主成分<script type="math/tex">\boldsymbol{y}</script>的协方差矩阵是对角矩阵:</p>
<script type="math/tex; mode=display">
\mathrm{cov}(\boldsymbol{y}) = \varLambda = \mathrm{diag}(\lambda_1,\lambda_2,\dots,\lambda_m) \tag{16-17}</script></li>
<li><p>总体主成分<script type="math/tex">\boldsymbol{y}</script>的方差之和等于随机变量<script type="math/tex">\boldsymbol{x}</script>的方差之和，即：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^m \lambda_i = \sum_{i=1}^m \sigma_{ii} \tag{16-18}</script><p>其中<script type="math/tex">\sigma_{ii}</script>是随机变量<script type="math/tex">x_i</script>的方差，即协方差矩阵<script type="math/tex">\Sigma</script>的对角元素。事实上，利用式(16-16)及矩阵的迹(trace)的性质，可知：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\sum_{i=1}^m \mathrm{var}(x_i) &= tr(\Sigma^{\top}) = tr(A\varLambda A^{\top}) = tr(A^{\top}\varLambda A)\\
&=tr(\varLambda) = \sum_{i=1}^m \lambda_i = \sum_{i=1}^m \mathrm{var}(y_i)
\end{aligned}\tag{16-19}</script></li>
<li><p>第k个主成分<script type="math/tex">y_k</script>与变量<script type="math/tex">x_i</script>的相关系数<script type="math/tex">\rho (y_k,x_i)</script>称为<strong>因子负荷量(factor loading)</strong>，它表示第k个主成分<script type="math/tex">y_k</script>与变量<script type="math/tex">x_i</script>的相关性。计算公式：</p>
<script type="math/tex; mode=display">
\rho(y_k,x_i) = \frac{\sqrt{\lambda_k}\alpha_{ik}}{\sqrt{\sigma_{ii}}} \ , k,i=1,2,\dots,m \tag{16-20}</script><p>因为</p>
<script type="math/tex; mode=display">
\rho(y_k,x_i) = \frac{\mathrm{cov}(y_k,x_i)}{\sqrt{\mathrm{var}(y_k)\mathrm{var}(x_i)}} = \frac{\mathrm{cov}(\alpha_k^{\top}\boldsymbol{x},e_i^{\top}\boldsymbol{x})}{\sqrt{\lambda_k}\sqrt{\sigma_{ii}}}</script><p>其中，<script type="math/tex">e_i</script>为基本单位向量，其第i个分量为1，其余分量为0.再由协方差的性质：</p>
<script type="math/tex; mode=display">
\mathrm{cov}(\alpha_k^{\top}\boldsymbol{x},e_i^{\top}\boldsymbol{x}) = \alpha_k^{\top}\Sigma e_i = e_i^{\top} \Sigma \alpha_k = \lambda_k e_i^{\top} \alpha_k = \lambda_k \alpha_{ik}</script><p>故得式(16-20)。</p>
</li>
<li><p>第k个主成分<script type="math/tex">y_k</script>与m个变量的因子负荷量满足：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^m \sigma_{ii}\rho^2(y_k,x_i) = \lambda_k \tag{16-21}</script><p>由式(16-20)有：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^m \sigma_{ii}\rho^2(y_k,x_i) = \sum_{i=1}^m \lambda_k \alpha_{ij}^2 = \lambda_k \alpha_k^{\top}\alpha_k = \lambda_k</script></li>
<li><p>m个主成分与第i个变量<script type="math/tex">x_i</script>的因子负荷量满足：</p>
<script type="math/tex; mode=display">
\sum_{k=1}^m \rho^2(y_k,x_i) = 1 \tag{16-22}</script><p>由于<script type="math/tex">y_1,y_2,\dots,y_m</script>互不相关，如：</p>
<script type="math/tex; mode=display">
\rho^2(x_i,(y_1,y_2,\dots,y_m)) = \sum_{i=1}^m \rho^2(y_k,x_i)</script><p>又因<script type="math/tex">x_i</script>可以表为<script type="math/tex">y_1,y_2,\dots,y_m</script>的线性组合，所以<script type="math/tex">x_i</script> 与<script type="math/tex">y_1,y_2,\dots,y_m</script>的相关系数的平方为1，式(16-22)得证。</p>
</li>
</ol>
<h3 id="主成分的个数"><a href="#主成分的个数" class="headerlink" title="主成分的个数"></a>主成分的个数</h3><p>主成分分析的主要目的是降维，所以一般选择k(<script type="math/tex">k \ll m</script>)个主成分(线性无关变量)来代替m个原有变量(线性相关变量)，使问题得以简化，并能保留原有变量的大部分信息。</p>
<blockquote>
<p><strong>信息是指原有变量的方差。</strong></p>
</blockquote>
<p><strong>定理16.2</strong> 对任意正整数q，<script type="math/tex">1\le q \le m</script>，考虑正交线性变换</p>
<script type="math/tex; mode=display">
\boldsymbol{y} = B^{\top}\boldsymbol{x} \tag{16-23}</script><p>其中<script type="math/tex">\boldsymbol{y}</script>是q维向量，<script type="math/tex">B^{\top}</script>是qxm矩阵，令<script type="math/tex">\boldsymbol{y}</script>的协方差矩阵为：</p>
<script type="math/tex; mode=display">
\Sigma_{\boldsymbol{y}} = B^{\top}\Sigma B \tag{16-24}</script><p>则<script type="math/tex">\Sigma_{\boldsymbol{y}}</script>的迹<script type="math/tex">tr(\Sigma_{\boldsymbol{y}})</script>在B=<script type="math/tex">A_q</script>时取得最大值，其中矩阵<script type="math/tex">A_q</script>由正交矩阵<script type="math/tex">A\in m\times m</script>的前q列组成。</p>
<p><strong>证明：</strong> </p>
<p>令<script type="math/tex">\beta_k</script>是B的第k列，由于正交矩阵A的列构成m维空间的基，所以<script type="math/tex">\beta_k</script>可以由A的列表示，即：</p>
<script type="math/tex; mode=display">
\beta_k = \sum_{j=1}^m c_{jk}\alpha_j</script><p>等价地</p>
<script type="math/tex; mode=display">
B = AC \tag{16-25}</script><p>其中C是mxq矩阵，其第j行第k列元素为<script type="math/tex">c_{jk}</script>。</p>
<p>首先，</p>
<script type="math/tex; mode=display">
B^{\top}\Sigma B = C^{\top}A^{\top}\Sigma AC = C^{\top}\varLambda C = \sum_{i=1}^m \lambda_jc_jc_j^{\top}</script><p>其中<script type="math/tex">c_j^{\top}</script>是C的第j行。因此</p>
<script type="math/tex; mode=display">
\begin{aligned}
tr(B^{\top}\Sigma B) &= \sum_{j=1}^m \lambda_j tr(c_jc_j^{\top})\\
&= \sum_{j=1}^m \lambda_j tr(c_j^{\top}c_j)\\
&= \sum_{j=1}^m \lambda_j c_j^{\top}c_j\\
&= \sum_{j=1}^m\sum_{k=1}^1 \lambda_j c_{jk}^2
\end{aligned}\tag{16-26}</script><p>其次，由式(16-25)及A的正交性知:</p>
<script type="math/tex; mode=display">
C = A^{\top}B</script><p>由于A是正交的，B的列是正交的，所以:</p>
<script type="math/tex; mode=display">
C^{\top}C = B^{\top}AA^{\top}B = B^{\top}B = I_q</script><p>即C的列也是正交的。于是</p>
<script type="math/tex; mode=display">
tr(C^{\top}C) = tr(I_q)</script><script type="math/tex; mode=display">
\sum_{j=1}^m \sum_{k=1}^q c_{jk}^2 = q \tag{16-27}</script><p>这样，矩阵C可以认为是某个m阶正交矩阵D的前q列。正交矩阵D的行也正交，所以满足:</p>
<script type="math/tex; mode=display">
d_j^{\top}d_j = 1 \ , j=1,2,\dots,m</script><p>其中<script type="math/tex">d_j^{\top}</script>是D的第j行。由于矩阵D的行包括矩阵C的行的前q个元素，所以：</p>
<script type="math/tex; mode=display">
c_j^{\top}c_j \le 1 \ , j=1,2,\dots,m</script><p>即</p>
<script type="math/tex; mode=display">
\sum_{k=1}^q c_{jk}^2 \le 1 \ , j=1,2,\dots,m \tag{16-28}</script><p>式(16-26)中<script type="math/tex">\sum_{k=1}^q c_{jk}^2</script>是<script type="math/tex">\lambda_j</script>的系数，由式(16-27)这些系数之和是q，且由式(16-28)知这些系数小于等于1.因为<script type="math/tex">\lambda_1\ge\lambda_2\ge\dots\ge\lambda_q\ge\dots\ge\lambda_m</script>，显然，当能找到<script type="math/tex">c_{jk}</script>使得</p>
<script type="math/tex; mode=display">
\sum_{k=1}^q c_{jk}^2 = \left\{\begin{aligned}&1,j=1,2,\dots,q\\&0,j=q+1,\dots,m\end{aligned}\right . \tag{16-29}</script><p>时，<script type="math/tex">\sum_{j=1}^m\left(\sum_{k=1}^q c_{jk}^2\right)\lambda_j</script>最大。而当<script type="math/tex">B=A_q</script>时，有</p>
<script type="math/tex; mode=display">
c_{jk} = \left\{\begin{aligned}&1,1\le j=k\le q\\&0,其它\end{aligned}\right.</script><p>满足式(16-29)。所以，当<script type="math/tex">B=A_q</script>时，<script type="math/tex">tr(\Sigma_{\boldsymbol{y}})</script>达到最大值。</p>
<p>定理16.2表明，当<script type="math/tex">\boldsymbol{x}</script>的线性变换<script type="math/tex">\boldsymbol{y}</script>在<script type="math/tex">B=A_q</script>时，其协方差矩阵<script type="math/tex">\Sigma_{\boldsymbol{y}}</script>的迹<script type="math/tex">tr(\Sigma_{\boldsymbol{y}})</script>取得最大值，也就是说，<strong>当取A的前q列(取<script type="math/tex">\boldsymbol{x}</script>的前q个主成分)时，能够最大限度地保留原有变量方差的信息</strong>。</p>
<p><strong>定理16.3</strong> 考虑正交变换</p>
<script type="math/tex; mode=display">
\boldsymbol{y} = B^{\top}\boldsymbol{x}</script><p>这里<script type="math/tex">B^{\top}</script>是pxm矩阵，A和<script type="math/tex">\Sigma_{\boldsymbol{y}}</script>的定义与定理16.2相同，则<script type="math/tex">tr(\Sigma_{\boldsymbol{y}})</script>在<script type="math/tex">B=A_p</script>时，取得最小值，其中矩阵<script type="math/tex">A_p</script>由A的后p列组成。</p>
<blockquote>
<p>定理16.3可以理解为：当舍弃A的后p列，即舍弃变量<script type="math/tex">\boldsymbol{x}</script>的后p个主成分时，原有变量的方差损失最少。</p>
</blockquote>
<p><strong>以上两个定理可以作为选择k个主成分的理论依据。具体选择k的方法，通常利用方差贡献率</strong>。</p>
<p><strong>定义16.2</strong> 第k主成分<script type="math/tex">y_k</script>的方差贡献率定义为<script type="math/tex">y_k</script>的方差与所有方差之和的比，记作<script type="math/tex">\eta_k</script>：</p>
<script type="math/tex; mode=display">
\eta_k = \frac{\lambda_k}{\sum_{i=1}^m \lambda_i} \tag{16.30}</script><p>k个主成分<script type="math/tex">y_1,y_2,\dots,y_k</script>的累计方差贡献率定义为k个方差之和与所有方差之和的比：</p>
<script type="math/tex; mode=display">
\sum_{i=1}^k \eta_i = \frac{\sum_{i=1}^k \lambda_i}{\sum_{i=1}^m \lambda_i} \tag{16-31}</script><p>通常取k使得累计方差贡献率达到某个阈值，比如70%～80%以上。<strong>累计方差贡献率反映了主成分保留信息的比例</strong>。</p>
<p>但不能反映对某个原有变量<script type="math/tex">x_i</script>的保留信息的比例，这时通常利用k个主成分<script type="math/tex">y_1,y_2,\dots,y_k</script>对原有变量<script type="math/tex">x_i</script>的贡献率。</p>
<p><strong>定义16.3</strong> k个主成分<script type="math/tex">y_1,y_2,\dots,y_k</script>对原有变量<script type="math/tex">x_i</script>的贡献率定义为<script type="math/tex">x_i</script>与<script type="math/tex">(y_1,y_2,\dots,y_k)</script>的相关系数的平方，记作<script type="math/tex">v_i</script></p>
<script type="math/tex; mode=display">
v_i = \rho^2(x_i,(y_1,y_2,\dots,y_k))</script><p>计算公式如下：</p>
<script type="math/tex; mode=display">
v_i = \rho^2(x_i,(y_1,y_2,\dots,y_k)) = \sum_{j=1}^k \rho^2(x_i,y_j) =\sum_{j=1}^k \frac{\lambda_j\alpha_{ij}^2}{\sigma_{ii}} \tag{16-32}</script><h3 id="规范化变量的总体主成分"><a href="#规范化变量的总体主成分" class="headerlink" title="规范化变量的总体主成分"></a>规范化变量的总体主成分</h3><p>在实际问题中，<strong>不同变量可能有不同的量纲</strong>，直接求主成分有时会产生不合理的结果。为了消除这个影响，需要对各个随机变量实施规范化，使其均值为0，方差为1.</p>
<p>设<script type="math/tex">\boldsymbol{x}=(x_1,x_2,\dots,x_m)^{\top}</script>为m维随机变量，<script type="math/tex">x_i</script>为第i个随机变量，i=1,2,…,m，令</p>
<script type="math/tex; mode=display">
x_i^{*} = \frac{x_i-E(x_i)}{\sqrt{\mathrm{var}(x_i)}} \ , i=1,2,\dots,m \tag{16-33}</script><p>其中，<script type="math/tex">E(x_i),\mathrm{var}(x_i)</script>分别是随机变量<script type="math/tex">x_i</script>的均值和方差，这时<script type="math/tex">x_i^{*}</script>就是<script type="math/tex">x_i</script>的规范化随机变量。</p>
<p>显然，规范化随机变量的协方差矩阵就是相关矩阵R。</p>
<p>对照总体主成分的性质可知，规范化随机变量的总体主成分分析有以下性质：</p>
<ol>
<li><p>规范化变量主成分的协方差矩阵是</p>
<script type="math/tex; mode=display">
\varLambda^{*} = \mathrm{diag}(\lambda_1^{*},\lambda_2^{*},\dots,\lambda_m^{*}) \tag{16-34}</script><p>其中<script type="math/tex">\lambda_1^*\ge\lambda_2^*\ge\dots\ge\lambda_m^*\ge0</script>为相关矩阵R的特征值。</p>
</li>
<li><p>协方差矩阵的特征值之和为m</p>
<script type="math/tex; mode=display">
\sum_{k=1}^m \lambda_k^* = m \tag{16-35}</script></li>
<li><p>规范化随机变量<script type="math/tex">x_i^*</script>与主成分<script type="math/tex">y_k^*</script>的相关系数(因子负荷量)为</p>
<script type="math/tex; mode=display">
\rho(y_k^*,x_i^*) = \sqrt{\lambda_k^*}e^*_{ik} \ , k,i=1,2,\dots,m \tag{16-36}</script><p>其中<script type="math/tex">e_k^* = (e_{1k}^*,e_{2k}^*,\dots,e_{mk}^*)^{\top}</script>为矩阵R对应的特征值<script type="math/tex">\lambda_k^*</script>对应的单位特征向量。</p>
</li>
<li><p>所有规范化随机变量<script type="math/tex">x_i^*</script>与主成分<script type="math/tex">y_k^*</script>的相关系数的平方和等于<script type="math/tex">\lambda_k^*</script></p>
<script type="math/tex; mode=display">
\sum_{i=1}^m \rho^2(y_k^*,x_i^*) = \sum_{i=1}^m \lambda_k^*e_{ik}^{*^2}=\lambda_k^* \ , k=1,2,\dots,m \tag{16-37}</script></li>
<li><p>规范化随机变量<script type="math/tex">x_i^*</script>与所有主成分<script type="math/tex">y_k^*</script>的相关系数的平方和等于1</p>
<script type="math/tex; mode=display">
\sum_{k=1}^m \rho^2(y_k^*,x_i^*) = \sum_{k=1}^m \lambda_k^*e_{ik}^{*^2}=1 \ , k=1,2,\dots,m \tag{16-38}</script></li>
</ol>
<h2 id="样本主成分分析"><a href="#样本主成分分析" class="headerlink" title="样本主成分分析"></a>样本主成分分析</h2><p>16.1是定义在样本总体上的主成分分析。</p>
<p>在实际问题中，需要在观测数据上进行主成分分析，也就是<strong>样本主成分分析</strong>。</p>
<h3 id="样本主成分的定义和性质"><a href="#样本主成分的定义和性质" class="headerlink" title="样本主成分的定义和性质"></a>样本主成分的定义和性质</h3><p>假设对m维随机变量<script type="math/tex">\boldsymbol{x} = (x_1,x_2,\dots,x_m)^{\top}</script>进行n次独立观测，<script type="math/tex">\boldsymbol{x}_1,\boldsymbol{x}_2,\dots,\boldsymbol{x}_n</script>表示观测样本，其中 <script type="math/tex">\boldsymbol{x}_j = (x_{1j},x_{2j},\dots,x_{mj})^{\top}</script>表示第j个样本，<script type="math/tex">x_{ij}</script>表示第j个观测样本的第i个变量，j=1,2,…,n。观测数据用样本矩阵<script type="math/tex">X</script>表示，记作：</p>
<script type="math/tex; mode=display">
X = [\boldsymbol{x}_1,\boldsymbol{x}_2,\dots,\boldsymbol{x}_n] =\begin{bmatrix}
   x_{11} & x_{12}&\dots&x_{1n} \\
   x_{21}&x_{22}&\dots&x_{2n}\\
   \vdots&\vdots&&\vdots\\
   x_{m1}&x_{m2}&\dots&x_{mn}
\end{bmatrix} \tag{16-39}</script><p>给定样本矩阵X，可以估计样本均值，以及样本协方差。样本均值向量 <script type="math/tex">\bar{x}</script>为</p>
<script type="math/tex; mode=display">
\bar{x} = \frac{1}{n} \sum_{j=1}^n \boldsymbol{x}_j \tag{16-40}</script><p>样本协方差矩阵S为：</p>
<script type="math/tex; mode=display">
S = [s_{ij}]_{m\times m}</script><script type="math/tex; mode=display">
s_{ij} = \frac{1}{n-1} \sum_{k=1}^n (x_{ik}-\bar{x}_i)(x_{jk}-\bar{x}_j) \ , i,j=1,2,\dots,m \tag{16-41}</script><p>其中<script type="math/tex">\bar{x}_i = \frac{1}{n}\sum_{k=1}^n x_{ik}</script>为第i个变量的样本均值，<script type="math/tex">\bar{x}_j=\frac{1}{n}\sum_{k=1}^n x_{jk}</script>为第j个变量的样本均值。</p>
<p>样本相关矩阵R为:</p>
<script type="math/tex; mode=display">
R = [r_{ij}]_{m\times m} \ , r_{ij} = \frac{s_{ij}}{\sqrt{s_{ii}s_{jj}}} \ , i,j = 1,2,\dots,m \tag{16-42}</script><p>定义m维向量<script type="math/tex">\boldsymbol{x} = (x_1,x_2,\dots,x_m)^{\top}</script>到m维向量<script type="math/tex">\boldsymbol{y} = (y_1,y_2,\dots,y_m)^{\top}</script>的线性变换</p>
<script type="math/tex; mode=display">
\boldsymbol{y} = A^{\top}\boldsymbol{x} \tag{16-43}</script><p>其中</p>
<script type="math/tex; mode=display">
A = [a_1,a_2,\dots,a_m] = \begin{bmatrix}
   a_{11} & a_{12}&\dots&a_{1m} \\
   a_{21}&a_{22}&\dots&a_{2m}\\
   \vdots&\vdots&&\vdots\\
   a_{m1}&a_{m2}&\dots&a_{mm}
\end{bmatrix}</script><script type="math/tex; mode=display">
a_i= (a_{1i},a_{2i},\dots,a_{mi})^{\top} \ , i=1,2,\dots,m</script><p>考虑式(16-43)的任意一个线性变换(对照式(16-1))</p>
<script type="math/tex; mode=display">
y_i = a_i^{\top}\boldsymbol{x} = a_{1i}x_1+a_{2i}x_2+\dots+a_{mi}x_m \tag{16-44}</script><p>其中<script type="math/tex">y_i</script>是m维向量<script type="math/tex">\boldsymbol{y}</script>的第i个变量，相应于容量为n的样本<script type="math/tex">\boldsymbol{x}_1,\boldsymbol{x}_2,\dots,\boldsymbol{x}_n</script>，<script type="math/tex">y_i</script>的样本均值<script type="math/tex">\bar{y}_i</script>为：</p>
<script type="math/tex; mode=display">
\bar{y}_i = \frac{1}{n} \sum_{j=1}^n a_i^{\top}\boldsymbol{x}_j = \alpha_i^{\top}\bar{\boldsymbol{x}} \tag{16-45}</script><p>其中<script type="math/tex">\bar{\boldsymbol{x}}</script>是随机变量<script type="math/tex">\boldsymbol{x}</script>的样本均值：</p>
<script type="math/tex; mode=display">
\bar{\boldsymbol{x}} = \frac{1}{n}\sum_{j=1}^n \boldsymbol{x}_j</script><p>其中，<script type="math/tex">y_j</script>的样本方差<script type="math/tex">\mathrm{var}(y_i)</script>为：</p>
<script type="math/tex; mode=display">
\begin{aligned}
\mathrm{var}(y_i) &= \frac{1}{n-1}\sum_{j=1}^n (a_i^{\top}\boldsymbol{x}_j-a_i^{\top}\bar{\boldsymbol{x}})^2\\
&= a_i^{\top}\left[\frac{1}{n-1}\sum_{j=1}^n(\boldsymbol{x}_j-\bar{\boldsymbol{x}})(\boldsymbol{x}_j-\bar{\boldsymbol{x}})^{\top}\right]a_i = c
\end{aligned}\tag{16-46}</script><p>对任意两个线性变换<script type="math/tex">y_i = a_i^{\top}\boldsymbol{x},y_k = a_k^{\top}\boldsymbol{x}</script>，对应于容量为n的样本<script type="math/tex">\boldsymbol{x}_1,\boldsymbol{x}_2,\dots,\boldsymbol{x}_n</script>，<script type="math/tex">y_i,y_k</script>的样本协方差为:</p>
<script type="math/tex; mode=display">
\mathrm{cov}(y_i,y_k) = a_i^{\top}Sa_k \tag{16-47}</script><p><strong>定义16.4(样本主成分)</strong> 给定样本矩阵<script type="math/tex">X</script>。样本第一主成分<script type="math/tex">y_1 = a_1^{\top}\boldsymbol{x}</script>是在<script type="math/tex">a_1^{\top}a_1=1</script>条件下，使得<script type="math/tex">a_1^{\top}\boldsymbol{x}_j</script> (j=1,2,…,n)的样本方差<script type="math/tex">a_1^{\top}Sa_1</script>最大的<script type="math/tex">\boldsymbol{x}</script>的线性变换；样本第二主成分<script type="math/tex">y_2 = a_2^{\top}\boldsymbol{x}</script>是在<script type="math/tex">a_2^{\top}a_2=1</script>和<script type="math/tex">a_2^{\top}\boldsymbol{x}_j</script>与<script type="math/tex">a_1^{\top}\boldsymbol{x}_j</script> (j=1,2,…,n)的样本协方差<script type="math/tex">a_1^{\top}Sa_2=0</script>条件下，使得<script type="math/tex">a_2^{\top}\boldsymbol{x}_j</script> (j=1,2,…,n)的样本方差<script type="math/tex">a_2^{\top}Sa_2</script>最大的<script type="math/tex">\boldsymbol{x}</script>的线性变换；**一般地，样本在第i主成分<script type="math/tex">y_i=a_i^{\top}\boldsymbol{x}</script>是在<script type="math/tex">a_i^{\top}a_i=1</script>和<script type="math/tex">a_i^{\top}\boldsymbol{x}_j</script>与<script type="math/tex">a_k^{\top}\boldsymbol{x}_j</script> (k&lt;i , j=1,2,…,n)的样本协方差<script type="math/tex">a_k^{\top}Sa_i=0</script>条件下，使得<script type="math/tex">a_i^{\top}\boldsymbol{x}_j</script> (j=1,2,…,n)的样本方差<script type="math/tex">a_i^{\top}Sa_i</script>最大的<script type="math/tex">\boldsymbol{x}</script>的线性变换。</p>
<p>在使用样本主成分时，一般假设样本数据是规范化的，即对样本矩阵作如下变换：</p>
<script type="math/tex; mode=display">
x_{ij}^{*} = \frac{x_{ij}-\bar{x}_i}{\sqrt{s_{ii}}} \ , i=1,2,\dots,m \ ; j=1,2,\dots,n \tag{16-48}</script><p>其中，</p>
<script type="math/tex; mode=display">
\bar{x}_i = \frac{1}{n} \sum_{j=1}^n \boldsymbol{x}_{ij} \ , i=1,2,\dots,m</script><script type="math/tex; mode=display">
s_{ii} = \frac{1}{n-1} \sum_{j=1}^n (x_{ij}-\bar{x}_i)^2 \ , i=1,2,\dots,m</script><p>这时，样本协方差矩阵S就是样本相关矩阵R：</p>
<script type="math/tex; mode=display">
R = \frac{1}{n-1}XX^{\top} \tag{16-49}</script><p><strong>样本协方差矩阵S是总体协方差矩阵<script type="math/tex">\Sigma</script>的无偏估计，样本相关矩阵R是总体相关矩阵的无偏估计，S的特征值和特征向量是<script type="math/tex">\Sigma</script> 特征值和特征向量的极大似然估计</strong>。</p>
<h3 id="相关矩阵的特征值分解算法"><a href="#相关矩阵的特征值分解算法" class="headerlink" title="相关矩阵的特征值分解算法"></a>相关矩阵的特征值分解算法</h3><p>给定样本矩阵X，利用数据的样本协方差矩阵或者样本相关矩阵的特征值分解进行主成分分析。具体步骤如下：</p>
<ol>
<li><p>对观测数据按式(16-48)进行规范化处理，仍以X表示</p>
</li>
<li><p>依据规范化数据矩阵，计算样本相关矩阵R</p>
<script type="math/tex; mode=display">
R = [r_{ij}]_{m\times m}= \frac{1}{n-1}XX^{\top}</script><p>其中，</p>
<script type="math/tex; mode=display">
r_{ij} = \frac{1}{n-1}\sum_{l=1}^n x_{il}x_{lj} \ ,\ i,j=1,2,\dots,m</script></li>
<li><p>求样本相关矩阵R的k个特征值和对应的k个单位特征向量。</p>
<p>求解R的特征方程</p>
<script type="math/tex; mode=display">
|R-\lambda I| = 0</script><p>得R的m个特征值</p>
<script type="math/tex; mode=display">
\lambda_1\ge\lambda_2\ge\dots\ge\lambda_m</script><p>求方差贡献率<script type="math/tex">\sum_{i=1}^k \eta_i</script>达到预定值的主成分个数k。</p>
<p>求前k个特征值对应的单位特征向量：</p>
<script type="math/tex; mode=display">
a_i = (a_{1i},a_{2i},\dots,a_{mi})^{\top} \ , i=1,2,\dots,k</script></li>
<li><p>求k个样本主成分</p>
<p>以k个单位特征向量为系数进行线性变换，求出k个样本主成分：</p>
<script type="math/tex; mode=display">
y_i = a_i^{\top}\boldsymbol{x} \ , i=1,2,\dots,k \tag{16-50}</script></li>
<li><p>计算k个主成分<script type="math/tex">y_j</script>与原变量<script type="math/tex">x_i</script>的相关系数<script type="math/tex">\rho(x_i,x_j)</script>，以及k个主成分对原变量<script type="math/tex">x_i</script>的贡献率<script type="math/tex">v_i</script>。</p>
</li>
<li><p>计算n个样本的k个主成分值</p>
<p>将规范化样本数据代入k个主成分式(16-50)，得到n个样本的主成分值。第j个样本<script type="math/tex">\boldsymbol(x)_j = (x_{1j},x_{2j},\dots,x_{mj})^{\top}</script>的第i主成分值是：</p>
<script type="math/tex; mode=display">
y_{ij} = (a_{1i},a_{2i},\dots,a_{mi})(x_{1j},x_{2j},\dots,x_{mj})^{\top} = \sum_{l=1}^m a_{li}x_{lj} \ i=1,2,\dots,m \ , j=1,2,\dots,n</script></li>
</ol>
<h3 id="数据矩阵的奇异值分解算法"><a href="#数据矩阵的奇异值分解算法" class="headerlink" title="数据矩阵的奇异值分解算法"></a>数据矩阵的奇异值分解算法</h3><p>给定样本矩阵X，利用数据矩阵奇异值分解进行主成分分析。具体过程如下。这里假设有k个主成分。</p>
<p>参照式(15-19)，对于mxn实矩阵A，假设其秩为r，0&lt;k&lt;r，则可以将矩阵A进行截断奇异值分解：</p>
<script type="math/tex; mode=display">
A \approx U_k\Sigma_kV_k^{\top}</script><p>式中<script type="math/tex">U_k</script>是mxk矩阵，<script type="math/tex">V_k</script>是nxk矩阵，<script type="math/tex">\Sigma_k</script>是k阶对角矩阵；<script type="math/tex">U_k</script>，<script type="math/tex">V_k</script>分别由取A的完全奇异值分解的矩阵U,V的前k列，<script type="math/tex">\Sigma_k</script>由取A的完全奇异值分解的矩阵<script type="math/tex">\Sigma</script>的前k个对角线元素得到。</p>
<p>定义一个新的nxm矩阵<script type="math/tex">X^{'}</script></p>
<script type="math/tex; mode=display">
X^{'} = \frac{1}{\sqrt{n-1}} X^{\top} \tag{16-51}</script><p>且<script type="math/tex">X^{'}</script>的每一个列均值为零。不难得知，</p>
<script type="math/tex; mode=display">
X^{'^{\top}}X^{'} = \left(\frac{1}{\sqrt{n-1}}X^{\top}\right)^{\top}\left(\frac{1}{\sqrt{n-1}}X^{\top}\right)=\frac{1}{\sqrt{n-1}}X X^{\top}\tag{16-52}</script><p>即<script type="math/tex">X^{'^{\top}}X^{'}</script>等于X的协方差矩阵<script type="math/tex">S_X</script>。</p>
<script type="math/tex; mode=display">
S_X = X^{'^{\top}}X^{'} \tag{16-53}</script><p>主成分分析归结于求协方差矩阵<script type="math/tex">S_X</script>的特征值和对应的单位特征向量，所以<strong>问题转化为求矩阵<script type="math/tex">X^{'^{\top}}X^{'}</script>的特征值和对应的单位特征向量</strong>。</p>
<p>假设<script type="math/tex">X^{'}</script>的截断奇异值分解为<script type="math/tex">X^{'}=U\Sigma V^{\top}</script>，那么V的列向量就是<script type="math/tex">S_X = X^{'^{\top}}X^{'}</script>的单位特征向量。因此，V的列向量就是X的主成分。</p>
<p>于是，求X主成分可以通过求<script type="math/tex">X^{'}</script>的奇异值分解来实现。具体算法如下：</p>
<p><strong>算法16.1(主成分分析算法)</strong></p>
<p>输入：mxn样本矩阵X，其每一行元素的均值为零</p>
<p>输出：kxn样本主成分矩阵Y</p>
<p>参数：主成分个数k</p>
<ol>
<li><p>构造新的nxm矩阵</p>
<script type="math/tex; mode=display">
X^{'} = \frac{1}{\sqrt{n-1}}X^{\top}</script><p>且<script type="math/tex">X^{'}</script>每一列的均值为零。</p>
</li>
<li><p>对矩阵<script type="math/tex">X^{'}</script>进行截断奇异值分解，得到：</p>
<script type="math/tex; mode=display">
X^{'} = U\Sigma V^{\top}</script><p>有k个奇异值、奇异向量。矩阵V 的前k列构成k个样本主成分。</p>
</li>
<li><p>求kxn样本主成分矩阵</p>
</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/无监督学习/" rel="tag"># 无监督学习</a>
          
            <a href="/tags/PCA/" rel="tag"># PCA</a>
          
            <a href="/tags/降维算法/" rel="tag"># 降维算法</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/08/24/svd/" rel="next" title="奇异值分解SVD">
                <i class="fa fa-chevron-left"></i> 奇异值分解SVD
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/09/01/lsa/" rel="prev" title="潜在语义分析">
                潜在语义分析 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    </div>

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">jozee</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">39</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">5</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">83</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#总体主成分分析"><span class="nav-number">1.</span> <span class="nav-text">总体主成分分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#基本想法"><span class="nav-number">1.1.</span> <span class="nav-text">基本想法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#定义和导出"><span class="nav-number">1.2.</span> <span class="nav-text">定义和导出</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主要性质"><span class="nav-number">1.3.</span> <span class="nav-text">主要性质</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#主成分的个数"><span class="nav-number">1.4.</span> <span class="nav-text">主成分的个数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#规范化变量的总体主成分"><span class="nav-number">1.5.</span> <span class="nav-text">规范化变量的总体主成分</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#样本主成分分析"><span class="nav-number">2.</span> <span class="nav-text">样本主成分分析</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#样本主成分的定义和性质"><span class="nav-number">2.1.</span> <span class="nav-text">样本主成分的定义和性质</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#相关矩阵的特征值分解算法"><span class="nav-number">2.2.</span> <span class="nav-text">相关矩阵的特征值分解算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#数据矩阵的奇异值分解算法"><span class="nav-number">2.3.</span> <span class="nav-text">数据矩阵的奇异值分解算法</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">jozee</span>

  
</div>
<div class="busuanzi_count">
    <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
    </script>
    <span> 本站访客数:<span id="busuanzi_value_site_uv"></span>人</span>
    <span class="post-meta-divider">|</span>
    <span>本站总访问量:<span id="busuanzi_value_site_pv"></span>次</span>
</div>









        






        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  

    
      <script id="dsq-count-scr" src="https://jozeelin.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://jozeelin.github.io/2019/08/28/pca/';
          this.page.identifier = '2019/08/28/pca/';
          this.page.title = 'PCA主成分分析';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://jozeelin.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  














  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
